{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_linear_regression_problem(samples_num):\n",
    "    bias = np.random.uniform(-5, 5)\n",
    "    data_noise = np.random.uniform(4, 8)\n",
    "    x_values, y_values = make_regression(n_samples=samples_num, n_features=1, noise=data_noise, bias=bias)\n",
    "    return x_values, y_values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_values, y_values = generate_linear_regression_problem(samples_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEXCAYAAABsyHmSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucXHV9//HXezd3crUETEIwFiI1QaQkIGKtiFjRYlHb\ntNIoYik8+EWrttZr6w/4ea219tf+NE3BC1IjSGoVaikU/GFpjdrspimSIBIVSCDAUnNZIG6S3U//\nOGeWs5OZ2bOTmTm7M+/n4zGPzJzLnO+Z3cxnv7fPVxGBmZlZPbqKLoCZmU1cDiJmZlY3BxEzM6ub\ng4iZmdXNQcTMzOrmIGJmZnVzELGKJL1U0n1Fl6MdSDpe0pOSuosuSy2SrpX0kRr7Q9KJrSxTPSQd\nK+kuSf2S/kLSByV9ruhytSsHkQ4n6QFJ55Zvj4h/i4iTiihTOUlXSjqYfhHvkbRR0ouLLldeEfFQ\nRMyMiMFGv3f6xf5U+tk8LOnT4z1YjWa0YJbDZcATwOyIeHdEfCwifj997yXpZzapIYU1BxEbX2r8\n5/5qRMwEjgbuBDa0+Prj2QvTz+YVwO8Cl5YfMEHvq17PAbaFZ1K3hIOIVSTpbEk7M68fkPTHku6W\ntFfSVyVNy+w/X9KWTE3hlMy+90v6cdq8sE3S6zP7Lpb0HUl/Kem/gStrlSsiDgHrgUWS5ue8/mmS\n/jO9/oa07B/J3qek90l6FPhijvd7X/pXf7+k+yS9It1+hqQeSfskPSbp0+n2EX/9Sloo6WZJP5O0\nXdKlmfe+UtKNkq5L33+rpJV5fmYR8UPg34CTMz+z90m6G3hK0iRJz5f07fS+tkr6jbK3OVrS7em1\n/1XScypdS9JUSZ+S9FB6r+skTS/7TN8r6XFJuyS9TtJrJP0ove8PVnnfy4DVwHvT2tU/pttHK3fp\n/GuBt2TOPzf9TL+cHnJX+u+edP+EqdGOWxHhRwc/gAeAcytsPxvYWXbcfwALgWcB9wKXp/t+GXgc\neBHQTfKf+AFgarp/VXpeF/A7wFPAgnTfxcAh4A+AScD0CmW5Evhy+nwK8AmS5opJo10/Pf5B4J3A\nZOANwAHgI5n7PAT8WXr89FHe7yRgB7AwPX8JcEL6/LvAm9PnM4EzM8dEprx3AWuBacCpQB9wTuZe\nfw68Jr32x4Hv1fj5BXBi+nwZ8ChwSeZntgVYnN7XZGA78MH0czkH6AdOSo+/Nn39q+m9/hXw71Wu\n9ZfAzSS/C7OAfwQ+XvaZ/u/0mpem9/iV9NjlwH7guVXu6drSzyd9XbPcOc6/kmd+f0b8LPxowHdI\n0QXwo+BfgLEFkTdlXn8SWJc+/xvgw2Xn3we8rMo1twAXpM8vBh4apYxXknzx7wEGgf8Gzs7sr3r9\n9AvxYUCZff/OyCByAJiW8/1OJAkw5wKTy465C7gKOLps+/AXF8kX+iAwK7P/48C1mXu9I7NvGbC/\nxmcTwD5gN/Bj4CNAV+Zn9nuZY19KEmS6MtuuB65Mn18L3JDZNzMt6+LMtU4ERPKHwAmZY18M/DTz\nme4HutPXs9JzX5Q5vhd4XZV7upaRQaBmuXOcfyUOIk17uDnLxuLRzPOnSb5kIGmDfnfa1LBH0h6S\nL8uFAJIuyjQN7SFpbjk68147clz7xoiYCxwL3AOsyOyrdf2FwMORfoNUuV5fRPw8z/tFxHbgXSRf\nTI9LukHSwvS8S4DnAT+UtEnS+RXuYyHws4joz2x7EFiUeV3+OU9T7T6N0yJiXkScEBF/GhFDVe51\nIbCjbH/5tYePj4gngZ+l52XNB2YAvZnP59Z0e8l/xzMDCfan/z6W2b+fZ35/RpOn3FYQBxFrhB3A\nRyNibuYxIyKuT9vUrwHeDvxCGgjuIflrtiR3B2hEPEEy+uZKSQtGuz6wi6T/JHu9xeVvm/d+0jJ8\nJSJ+hSTYBElTGBFxf0RcCByTbvt7SUeVvfcjwLMkzcpsO56kttQM2Xt7BFgsKfv/vvzaw5+NpJkk\nzVWPlL3nEyRBYHnm85kTSed+o8uct9z1vrcdIQcRA5gsaVrmMdaRPNcAl0t6kRJHSfr19IvyKJL/\nuH0Akt5K2vFbr4i4D7gNeG+O63+XpEnm7WnH8gXAGfXej6STJJ0jaSpJ38V+YCi9tzdJmp/+xbwn\nfa/sX89ExA5gI/Dx9LM+haQG82Wa7/skNZv3Spos6WzgtcANmWNeI+lXJE0BPkzSHzOi5pbe3zXA\nX0o6BkDSIkmvalA5HwN+cYzlzquP5Gfyi6MdaPk4iBjALSRfhqXHlWM5OSJ6SDpPP0PSNr+dpK+D\niNgG/AXJl/ljwAuA7zSgzH8OXCbpmFGuf4CkM/0Ski/2NwHfBAbquR+SDudSx/6jJLWOD6T7zgO2\nSnqSpFP6jRGxn8NdSNI2/wjwdeCKiLhjjPc/Zuln8Vrg1STlXwtcFMmorpKvAFeQNGOtIPm8Knkf\nyefyPUn7gDtIBh00wueBZWlT2TdyljuXiHga+CjwnfT9z2xQmTuWRjYVm7U/Sd8nGRTwxaLLYjbR\nuSZibU/SyyQ9O23OegtwCklHsJkdoU6axWqd6yTgRpL+mZ8AvxURu4otkll7cHOWmZnVzc1ZZmZW\nt7Zvzjr66KNjyZIlRRfDzGxC6e3tfSIi5o92XNsHkSVLltDT01N0MczMJhRJD+Y5zs1ZZmZWNwcR\nMzOrm4OImZnVzUHEzMzq5iBiZmZ1cxAxM7O6tf0QXzOzTtPXP8Ca9b1s27WPZQtms3b1CubPmtqU\nazmImJm1iVLw6H1wN0NpRqvND+1mzfpeNlx+VlOu6eYsM7M2sWZ9L5sfeiaAAAwOwbZd+5p2TQcR\nM7M2sW3XPgaHRm7r7oJlC2Y37ZoOImZmbWLZgtl0Z77VuwSnHT+PtatXNO2a7hMxM2sTa1evaFmH\neomDiJlZm5g/a2rTOtCrcXOWmZnVzUHEzMzq5iBiZmZ1cxAxM7O6OYiYmVndHETMzKxuDiJmZlY3\nBxEzM6ubg4iZmdXNQcTMzOrmIGJmZnVzEDEzs7oVGkQkLZZ0p6RtkrZKeme6/VmSbpd0f/rvvHS7\nJP21pO2S7pZ0WpHlNzPrdEXXRA4B746IZcCZwNskLQPeD3wrIpYC30pfA7waWJo+LgP+pvVFNjOz\nkkKDSETsiojN6fN+4F5gEXAB8KX0sC8Br0ufXwBcF4nvAXMlLWhxsc3MLFV0TWSYpCXALwPfB46N\niF3prkeBY9Pni4AdmdN2ptvK3+syST2Sevr6+ppWZjOzTjcugoikmcDXgHdFxIgV5SMigKh4YhUR\ncXVErIyIlfPnz29gSc3MLKvwICJpMkkAWR8R/5BufqzUTJX++3i6/WFgceb049JtZmZWgKJHZwn4\nPHBvRHw6s+tm4C3p87cAN2W2X5SO0joT2Jtp9jIzsxYreo31lwBvBn4gaUu67YPAJ4AbJV0CPAj8\ndrrvFuA1wHbgaeCtrS2umZllFRpEIuLfAVXZ/YoKxwfwtqYWyszMciu8T8TMzCYuBxEzM6ubg4iZ\nmdXNQcTMzOrmIGJmZnUreoivmVmh+voHWLO+l2279rFswWzWrl7B/FlTiy7WhOGaiJl1tDXre9n8\n0G6eGhhk80O7WbO+t+giTSgOImbW0bbt2sfgUPJ8cCh5bfk5iJhZR1u2YDbd6Tdhd1fy2vJzEDGz\njrZ29QpOO34eR03t5rTj57F29YqiizShuGPdzDra/FlT2XD5WUUXY8JyTcTMzOrmIGJmZnVzEDEz\ns7o5iJiZWd0cRMzMrG4OImZmVjcP8TWzCaGvf4BLr+vh7p17AJg2uRsIli+c43xXBXJNxMwmhDXr\ne9myYw9DAUMBTx8Y5OkDQ853VTAHETObEKrltHK+q2I5iJjZuNDXP8CqdRtZfsWtrFq3kb7+gRH7\nq+W0cr6rYjmImFnLVQoYo6VkX7t6BacunkuXoEswY0o3M6Z0Od9VwRQRRZehqVauXBk9PT1FF8PM\nMlat28jmh3YzOFQKCJN4cuDQiGOOmtrN1qvOK6iEJqk3IlaOdpxHZ5lZy2XX8BgKDgsg2SYqrzw4\nvrk5y8xaLruGRyXZJiqvPDi+OYiYWctl1/CYOXUS3Uq2d3fB6UvmseHys4ZrG155cHxzc5aZtVx2\nDY9KzVVZyxbMHu4/8Uis8ccd62Y2rrlPpBjuWDeztuCVB8c394mYmVndHETMzKxubs4ys0K4r6M9\nuCZiZoXw/I/24CBiZoXw/I/24CBiZoXIzlr3/I+Jy0HEzAqRnbXuTLwTlzvWzWzMGtEp7vkf7aHw\nmoikL0h6XNI9mW3PknS7pPvTf+el2yXpryVtl3S3pNOKK7lZ53KnuJUUHkSAa4HyRQPeD3wrIpYC\n30pfA7waWJo+LgP+pkVlNLMMd4pbSeFBJCLuAn5WtvkC4Evp8y8Br8tsvy4S3wPmSlrQmpKaWYk7\nxa2k8CBSxbERsSt9/ihwbPp8EbAjc9zOdNsIki6T1COpp6+vr7klNetA7hS3knHfsR4RIWlMqYYj\n4mrgakiy+DalYGYdzJ3iVjJeg8hjkhZExK60uerxdPvDwOLMccel28ysQZyOxMZivDZn3Qy8JX3+\nFuCmzPaL0lFaZwJ7M81eZtYAHnllY1F4EJF0PfBd4CRJOyVdAnwCeKWk+4Fz09cAtwA/AbYD1wBr\nCiiy2bjX1z/AqnUbWX7Fraxat5G+/oHc55aPvNr0wO4xv4d1Dq9saNaGVq3bOGJJ2dOOn5e7DyN7\nbslY38MmvrwrGxZeEzGzxjuSeRylkVdZngti1TiImLWhPPM4qjV5lUZenb5knueC2KgcRMza0Icv\nOJnpk5PBl9MnT+LDF5x82DGVOtCzgeXg4BAvWDTXc0GsJgcRszb0oZvuYf/BQwDsP3iID910z2HH\nVGryygaWHzy8l8ndYutV57Hh8rM8zNcqchAxazN9/QP0Prh71D6RSk1eWx/ZO+K8rY/sbVGpbaJy\nEDFrM2vW9zJUNuhy/4HBEf0eff0DHBwMIqBL8IJFc1i7egVdGvmVUP7arJx/Q8zaTKVax1AwYuLg\nmvW9/ODhPQwFSDC5u4v5s6YyVDbkv/y1WTkHEbNxqt4Jg9lmqqxss1a1ZqvlC0c2cS1f6BFZVpuD\niNk4lSf9SKVAk82wO3PqJLqUHJsdplut2crZeW2scgURSZ+UNFvSZEnfktQn6U3NLpxZJ8szYbBS\noJk/ayprV69g2YLZDEUwY8okZkzpGhEUqjVbleaIeESW5ZW3JvJrEbEPOB94ADgReE+zCmVm+SYM\nlgea3gd3D2fh3fzQbp4+MMj+g4dYvnDOiKDgZitrlLxBpJQy/teBDRHhcX9mTZanaak8sAwFw2nc\na9Vi3GxljZIrAaOkT5AsUbsfOAOYC3wzIl7U3OIdOSdgtHbW1z/Aiz52x4ghvUdN7WbZgtl1J2A0\ngwYnYIyI9wNnASsj4iDwNMl652ZWgFKH+tmfupMZUw7vPHdNw1ol18qGkmaQrN1xPHAZsBA4Cfhm\n84pmZtWU+jwGh6BbMGPKJIIYsRKhax7WCnmXx/0i0EtSG4FkSdoNOIiYFWJEn0dAEGy96rxiC2Ud\nKW/H+gkR8UngIEBEPA2oaaUys5ryjNwya4W8QeSApOlAAEg6AfBamWYFyZPq3awV8jZnXQHcCiyW\ntB54CXBxswpl1sn6+ge49LpN3L0zGUl/ynFzueailSMm/lVK9e4+ECtCriASEbdL2gycSdKM9c6I\neKKpJTPrEKXJgdt27WPpMTO5/7EneerA4PD+LTv28PJPfZs7//js4UByJMvfmjVS3rQnvwosB/qB\nfcCydJuZHaFs6pItO/aOCCAlTw4cGpE7y30iNl7k7RN5T+bxIeAfgSubVCazjpKtVdSy6YHdFZMs\neh6IFSlvc9Zrs68lLQb+b1NKZNZhlh4zky078mUSKiVZ3HD5We4DsXGh3lTwO4HnN7IgZp2r+mj5\nGVO6R7z2krU23uSdsf7/SIf3kgSeU4HNzSqUWSe5//H+qvskmDl1Ek8OHBre5iVrbTzJO8Q3m8Hw\nEHB9RHynCeUxm/Cyo62yaUiqySZLzCp1mG99ZOTIKy9Za+NJ3j6RLzW7IGbtIpvXKtuHAeXDeWdx\ncHCQe3f1MxTQJXj+gllM7u7m/sf7hwPQiDxZXvvDxpmaQUTSD3imGWvELiAi4pSmlMpsAqs2h6Ov\nf4CXf+rbw01TW3bsGXHeUCSJFMs7zEuBJFuzMRsvRquJnN+SUpi1kfK1PEpzONas7x3Rt1FJpUmD\nzshr41nNIBIRD7aqIGbtolrNIc+sck8atIkm74z1MyVtkvSkpAOSBiU5z4JZmVqd6ssWzB5ePAoY\n8RzgqCndbqqyCSfvWMHPABcC9wPTgd8HPtusQplNVNkUJqVO9ZK1q1ew4jnJLPPTl8zjlne8lNOX\nPPP62+95ec1RXGbjUd4hvkTEdkndETEIfFHSfwIfaF7RzCaeWokRK/VtuK/DJrq8NZGnJU0Btkj6\npKQ/HMO5Zh3DiRGt0+QNBG9Oj3078BSwGPjNZhXKbKJyYkTrNHmbs1YA/xQR+4CrmlgeswnNw3Gt\n0+StibwW+JGkv5N0vqTcfSlm411f/wCr1m1k+RW3DqdaN7N8cgWRiHgrcCKwgWSU1o8lfa6ZBTNr\nlVojqsysttyd4xFxEPhn4AagF3hdswo1GknnSbpP0nZJ7y+qHNYevNSsWf3yTjZ8taRrSeaJ/Cbw\nOeDZTSxXrbJ0k8xReTWwDLhQ0rIiymLtodKIKjdxmeWTtyZyEfAN4KSIuDgibomI2kmAmucMYHtE\n/CQiDpDUjC4oqCzWBiqNqHITl1k+eftELoyIb0RExT/HJH23scWqaRGwI/N6Z7otW57LJPVI6unr\n62th0axduInLLJ9GTRic1qD3aYiIuDoiVkbEyvnz5xddHBvnKtU6PGnQLJ9GBZFWLrX2MMlkx5Lj\n0m1mdalU6/CkQbN8JuJ8j03AUknPJQkebwR+t9gi2US2bMFseh/czVD6p5BI0ut60qDZ6PKOzvoD\nSfNqHdKg8owq7dB/O3AbcC9wY0RsbdX1rf2sXb2CGVOe+Xtq/4FD7kg3yylvTeRYYJOkzcAXgNsi\nItuE9eaGl6yGiLgFuKWV17T2NX/WVCLTIjsYIzvSa60RYtbp8o7O+lNgKfB54GLgfkkfk3RCuv+e\nppXQrAVqdaR7uK9ZdWNZTyQkPQo8ChwC5gF/L+n2iHhvswpoVo9S7WHrI3vpUhdDESxfOJsPX3Ay\nH7rpnsNqFdWWtAUP9zWrRSNbpaocJL2TZMLhEySz1b8REQcldQH3R8QJzS1m/VauXBk9PT1FF8Oa\nrK9/gEuv28TdO/cCMH1yN/sPDg53lkNSw5g+eRL7Dx5icCh5fdrx80btQF+1biObH9o9pnPMJjpJ\nvRGxcrTj8g7xfRbwhoh4VURsSPNoERFDwPlHUE6zhlizvpctO/YyFDAU8NSBkQEEklrEkwOHxlyr\n8HBfs+pyNWdFxBU19t3buOKY1WfrI3tzHdclkBiuVeSZROg1Qsyq8xK3NuH9cNc+nj4wdNj2rgoD\nz6dO6nKtwqyBJuJkQ+tw5UNutz5SuUlq2uQuli+cM6I/4+RFc1yrMGsg10RsXKuUkn3EkNsHd/P0\ngcGK5y5fOMf9GWZNlmt01kTm0VkTW6WRUdt27eOpgcqBo+TUxXO45qLTPSnQrE55R2e5OcvGtUpz\nNJYtmD0cWCq59Z0v5ZecddesJdycZeNa+UzypcfM5OBgEJF0nM+Y0j3cgd4lmDl1Er+5bqNXIzRr\nEQcRG9c+fMHJTJvUDSQ1kR891s8Pdu5hKJKhus87dhYrnpP0ecyYMon9Bw45PYlZC7k5y8a1D910\nD09lOs6zQ3kHh+D+x/vZetV5ACy/4lYG45l9Tk9i1nyuidi4VmsSYflkQa9GaNZ6DiLWMpWG645G\nVZaq6RKHDdn1cF6z1nNzlrVMaX7H4BDDfRajTfzbf7DyUN5pk7sPO9fpScxaz0HEWqZWSvWxLvzU\npZYtpmlmNbg5y1qmnoWfTjluTsX3Gooqk0TMrKUcRKxlavVZVKulXHPR6Zy+ZN6IZIrdXUlKEzMr\nnpuzrGVq9VlkZ6Fnaymlcyo1d5lZ8Zw7y5ouT3/HWPtEzKy58ubOchCxpvPysmYTjxMwWkvVqknU\nGpVlZhObO9atIaqNroKRo7IA9h8YdIJEszbhIGINUau2URqVVRphNRQ4QaJZm3AQsYaoNQekNMJq\n+pTu4W1u1jJrDw4idsT6+gdGrPHxgkVzKg7BdYJEs/bjIGJH7NLrNrFlR7LGx1DAf+3Yy5r1vYf1\neThBoln78egsG9Voczju3jkyXXtQOcGiEySatR/XRGxUtUZeVeM+D7PO4CBiVZXW/9j0wO6a2Xen\nT+4+7Fz3eZh1BjdnWVWlGkhWpey72TU/ugTTJnexfGHlznUzay8OIlZVdu5HSaXsu0NlmXP+9T3n\nOO+VWYdwc5ZVVT4k9/Qlz+S8Ki1zW7587VDgSYRmHcRBxKqqNiQ329G+/8Chw85zh7pZ53BzllVV\nbUjuiBQn6QRDicPWAjGz9ueaiI1ZeTPXKcfN9SRCsw5VWE1E0irgSuD5wBkR0ZPZ9wHgEmAQeEdE\n3JZuPw/4K6Ab+FxEfKLV5e5U2QmHS4+ZyQsWzeX+x/u9gJRZhyuyOese4A3A32Y3SloGvBFYDiwE\n7pD0vHT3Z4FXAjuBTZJujohtrStye6hnFcFSP8jgEPzg4b2cdvw8tl51XotKbGbjVWHNWRFxb0Tc\nV2HXBcANETEQET8FtgNnpI/tEfGTiDgA3JAea2NUzwx0LyxlZpWMxz6RRcCOzOud6bZq222MygPC\npgd2j7pIlDPwmlklTQ0iku6QdE+FR1NrEJIuk9Qjqaevr6+Zl5qQylcahNEXiXIGXjOrpKl9IhFx\nbh2nPQwszrw+Lt1Gje3l170auBpg5cqVUemYTrZ29QrWrO9l0wPPpDQZrYnKGXjNrJLx2Jx1M/BG\nSVMlPRdYCvwHsAlYKum5kqaQdL7fXGA5J6xSQDh9yTw3UZnZESksiEh6vaSdwIuBf5J0G0BEbAVu\nBLYBtwJvi4jBiDgEvB24DbgXuDE91urkJiozO1KKaO/WnpUrV0ZPT8/oB5qZ2TBJvRGxcrTjnPak\njZVPEAR5gqCZNdR47BOxBsnOB9myYy9bduwZ09wQM7PROIi0sUrrgYAnC5pZ47g5q01USmWybMHs\n4VQlWR6JZWaN4iAyAVUKGNncVqXmqtL2an0iZmZHykFkAqoUMCrltvIEQTNrNveJTECVAoZzW5lZ\nERxEJqBKAcMTB82sCJ5sOM7kWeujnvVAzMzGIu9kQweRcWbVuo3D/R3dXXDa8fPcr2FmLZc3iLg5\na5zZ+sjeEf0dWx/ZW2yBzMxq8OisgpU3TQmN2N+l2nHeTVtmViTXRApWvlTt/oODI/YPjdLcWM9S\nt2ZmjeIgUrDy4brAiJFXyxfWHqrrtc/NrEgOIgUrH657ynFzxjRU1/NDzKxI7hMpWDY1ST19GpXO\nNzNrFQ/xNTOzw3iIr5mZNZ2DiJmZ1c1BxMzM6uYgYmZmdXMQMTOzujmImJlZ3RxEzMysbg4iZmZW\nN89YbzBn1TWzTuKaSIM5q66ZdRIHkQZzVl0z6yQOIg3mrLpm1kkcRKro6x9g1bqNLL/iVlat20hf\n/0Cu89auXjGmVO5mZhOZs/hWsWrdRjY/uJvB9OOZOXUSd/7x2Yd1krsj3czakbP4HqFtu/YNBxCA\nJwcOcel1mw47zh3pZtbJHESqqNSXcffOvYdtc0e6mXUyB5Eq8vZluCPdzDqZg0gV82dN5dTFc0ds\nO+W4uYcd5450M+tk7livwZ3mZtap8nasO+1JDfNnTWXD5WcVXQwzs3HLzVlmZla3woKIpD+X9ENJ\nd0v6uqS5mX0fkLRd0n2SXpXZfl66bbuk9xdTcjMzKymyJnI7cHJEnAL8CPgAgKRlwBuB5cB5wFpJ\n3ZK6gc8CrwaWARemx5qZWUEKCyIR8S8RcSh9+T3guPT5BcANETEQET8FtgNnpI/tEfGTiDgA3JAe\na2ZmBRkvfSK/B/xz+nwRsCOzb2e6rdr2w0i6TFKPpJ6+vr4mFNfMzKDJo7Mk3QE8u8KuP4mIm9Jj\n/gQ4BKxv1HUj4mrgakiG+Dbqfc3MbKSmBpGIOLfWfkkXA+cDr4hnJqw8DCzOHHZcuo0a26vq7e19\nQtKDect8hI4GnmjRtcaDTrpf32t78r1W95w8BxU22VDSecCngZdFRF9m+3LgKyR9IAuBbwFLAZF0\nwL+CJHhsAn43Ira2uOhVSerJMzmnXXTS/fpe25Pv9cgVOdnwM8BU4HZJAN+LiMsjYqukG4FtJM1c\nb4uIQQBJbwduA7qBL4ynAGJm1okKCyIRcWKNfR8FPlph+y3ALc0sl5mZ5TdeRme1i6uLLkCLddL9\n+l7bk+/1CLV9AkYzM2se10TMzKxuDiJmZlY3B5EGq5VYst1IWiVpq6QhSW05TLKTkn5K+oKkxyXd\nU3RZmk3SYkl3StqW/g6/s+gyNYukaZL+Q9J/pfd6VSPf30Gk8SomlmxT9wBvAO4quiDN0IFJP68l\nSXraCQ4B746IZcCZwNva+Gc7AJwTES8ETgXOk3Rmo97cQaTBaiSWbDsRcW9E3Fd0OZqoo5J+RsRd\nwM+KLkcrRMSuiNicPu8H7qVKLr6JLhJPpi8np4+GjahyEGmubGJJm3hyJ/20iUvSEuCXge8XW5Lm\nSZfT2AI8DtweEQ27Vy+PW4eiEksWIc+9mk1UkmYCXwPeFRH7ii5Ps6RZP05N+2i/LunkiGhI35eD\nSB3qTCw5IY12r22uVjJQm+AkTSYJIOsj4h+KLk8rRMQeSXeS9H01JIi4OavB0sSS7wV+IyKeLro8\ndkQ2AUslPVfSFJIVN28uuEzWAEoS9n0euDciPl10eZpJ0vzSKFFJ04FXAj9s1Ps7iDTeZ4BZJIkl\nt0haV3SBmkXS6yXtBF4M/JOk24ouUyOlAyRKST/vBW5s56Sfkq4HvgucJGmnpEuKLlMTvQR4M3BO\n+v90i6RAkBCqAAACWUlEQVTXFF2oJlkA3CnpbpI/jG6PiG826s2d9sTMzOrmmoiZmdXNQcTMzOrm\nIGJmZnVzEDEzs7o5iJiZWd0cRMzMrG4OImYFkrSkE1KvW/tyEDEzs7o5iJjlIOn0dKGxaZKOShf3\nObnCcTdI+vXM62sl/VZa4/g3SZvTx1kVzr1Y0mcyr78p6ez0+a9J+m567oY0cSCSPpEurHS3pE81\n5ebNanACRrMcImKTpJuBjwDTgS9XyYL6VeC3SdLATAFeAfwvQMArI+LnkpYC1wO5VoOUdDTwp8C5\nEfGUpPcBfyTps8DrgV+KiGjnVTRt/HIQMcvv/5DkHvo58I4qx/wz8FeSppJkSr0rIvZLmgN8RtKp\nwCDwvDFc90ySlRW/k+QNZApJjqu9aVk+L+mbQMPyIZnl5SBilt8vADNJVoabBjxVfkBa0/g28Crg\nd0hWQwT4Q+Ax4IUkzcg/r/D+hxjZxDwt/VckSfMuLD9B0hkktZ3fIkkWec5Yb8rsSLhPxCy/vwU+\nRLLQ2J/VOO6rwFuBlwK3ptvmALsiYogke2x3hfMeIFk4qEvSYpLleSFZZvklkk4ESPtknpf2i8yJ\niFtIgtQLj+TmzOrhmohZDpIuAg5GxFckdQMbJZ0TEf+/wuH/AvwdcFO6NjvAWuBr6fvcSoVaDPAd\n4KfANpLU86U1wPvShc6uT5vJIOkj6QdukjSNpLbyRw24VbMxcSp4MzOrm5uzzMysbm7OMquDpBeQ\nNFllDUTEi4ooj1lR3JxlZmZ1c3OWmZnVzUHEzMzq5iBiZmZ1cxAxM7O6/Q+CexPJ1KYeNQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b630dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Presenting generated data\n",
    "plt.scatter(x_values, y_values, s=15)\n",
    "plt.title(\"Linear Regression Problem to fit\")\n",
    "plt.xlabel(\"x_values\")\n",
    "plt.ylabel(\"y_values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating cost function as Mean Squared Errors:\n",
    "\n",
    "\\begin{equation*}\n",
    " MSE   = \\frac{1}{2m} \\sum_{i=1}^m (h_{\\theta}(x_i) - y_i)^2\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " - x - input to classifier\n",
    " - y - ideal output for given x\n",
    " - θ - weight for x representing feature\n",
    " - m - number of all samples \n",
    " - i - index of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_errors(X, y, theta):\n",
    "    samples_num = len(X)\n",
    "    predictions = np.dot(X, theta)\n",
    "    square_error = np.sum(np.square(predictions - y))\n",
    "    return square_error / (2 * samples_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent for used (above) MSE equation.\n",
    "\n",
    "Repeat until model converges:\n",
    "\n",
    "\\begin{equation*}\n",
    " \\theta_0 = \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x_i) - y_i)x_0\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    " \\theta_1 = \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x_i) - y_i)x_1\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    " ...\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    " \\theta_n = \\theta_n - \\alpha\\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x_i) - y_i)x_n\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " - α - learning rate\n",
    " - x - input to classifier\n",
    " - y - ideal output for given x\n",
    " - θ - weight for x representing feature\n",
    " - m - number of all samples \n",
    " - i - index of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, iterations, learning_rate):\n",
    "    # Container for error from each gradient step\n",
    "    error_history = []\n",
    "    \n",
    "    # Calculating initial error and saving it\n",
    "    initial_error = mean_squared_errors(X, y, theta)\n",
    "    error_history.append(initial_error)\n",
    "    \n",
    "    # Performing gradient step 'iterations' times\n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # Updating theta values\n",
    "        theta = gradient_step(X, y, theta, learning_rate)\n",
    "        \n",
    "        # Calculating and saving error from current gradient step\n",
    "        error = mean_squared_errors(X, y, theta)\n",
    "        error_history.append(error)\n",
    "        \n",
    "        # Displaying train progress\n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration no. \" + str(i) + \", error: \" + str(error))\n",
    "        \n",
    "    return theta, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vector implementation (without using loops) of gradient equations above\n",
    "def gradient_step(X, y, theta, learning_rate):\n",
    "    theta_num = len(theta)\n",
    "    samples_num = len(X)\n",
    "    predictions = np.dot(X, theta)\n",
    "    grad_delta = (1 / samples_num) * np.dot(X.T, predictions - y)\n",
    "    theta = theta - learning_rate * grad_delta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    " h(x) = \\theta_0 + \\theta_1x\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding bias column (column of ones) to input values\n",
    "bias = np.ones(len(x_values))\n",
    "X = np.column_stack((bias, x_values))\n",
    "\n",
    "# Specifying ideal outputs\n",
    "y = y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for model\n",
    "theta = np.zeros((X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,1) (100,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d7a25c2bae2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Performing gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrained_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-67a70b41adef>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(X, y, theta, iterations, learning_rate)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Updating theta values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Calculating and saving error from current gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1ae8e79f15b5>\u001b[0m in \u001b[0;36mgradient_step\u001b[0;34m(X, y, theta, learning_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msamples_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrad_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msamples_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (100,2) "
     ]
    }
   ],
   "source": [
    "# Performing gradient descent\n",
    "trained_theta, error_history = gradient_descent(X, y, theta, iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model learning history\n",
    "plt.plot(error_history)\n",
    "plt.title(\"Error per iteration\")\n",
    "plt.ylabel('MSE Error')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hypothesis(x, trained_theta):\n",
    "    return trained_theta[0][0] + trained_theta[1][0] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Displaying dataset\n",
    "plt.scatter(x_values, y_values, s=15)\n",
    "\n",
    "# Displaying aproximated function\n",
    "min_x = np.min(x_values)\n",
    "max_x = np.max(x_values)\n",
    "function_x = np.arange(min_x, max_x, 0.01)\n",
    "function_y = [hypothesis(x, trained_theta) for x in function_x]\n",
    "plt.plot(function_x, function_y, c=\"red\")\n",
    "\n",
    "# Displaying predicted values\n",
    "y_predicted = np.dot(X, trained_theta)\n",
    "plt.scatter(x_values, y_predicted, s=20, c='red')\n",
    "\n",
    "plt.title(\"Regression line\")\n",
    "plt.ylabel(\"y values\")\n",
    "plt.xlabel(\"x values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify ranges for cost grid calculation\n",
    "theta0_rounded = int(round(trained_theta[0][0]))\n",
    "theta1_rounded = int(round(trained_theta[1][0]))\n",
    "theta0_linspace = np.linspace(-100, theta0_rounded/10, 100)\n",
    "theta1_linspace = np.linspace(-100, theta1_rounded/10, 100)\n",
    "\n",
    "theta0_linspace_values, theta1_linspace_values = np.meshgrid(theta0_linspace, theta1_linspace, indexing='xy')\n",
    "theta_cost_grid = np.zeros((theta0_linspace.size, theta1_linspace.size))\n",
    "\n",
    "# Calculate cost values for every point of grid\n",
    "for (i,j),v in np.ndenumerate(theta_cost_grid):\n",
    "    theta_cost_grid[i,j] = mean_squared_errors(X, y, [[theta0_linspace_values[i,j]], [theta1_linspace_values[i,j]]])\n",
    "\n",
    "# Creating figure\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Displaying plot\n",
    "ax.plot_surface(theta0_linspace_values, theta1_linspace_values, theta_cost_grid, rstride=1, cstride=1, alpha=0.7, cmap=plt.cm.jet)\n",
    "ax.set_zlabel('Cost')\n",
    "ax.set_zlim(theta_cost_grid.min(), theta_cost_grid.max())\n",
    "ax.view_init(elev=15, azim=230)\n",
    "\n",
    "# Labels\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel(r'$\\theta_0$', fontsize=17)\n",
    "    ax.set_ylabel(r'$\\theta_1$', fontsize=17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
