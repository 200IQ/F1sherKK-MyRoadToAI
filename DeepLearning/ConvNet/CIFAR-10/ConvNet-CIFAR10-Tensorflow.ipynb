{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 is a dataset of 60 000 32x32 colour images, collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. There are 10 different classes with 6000 images per class:\n",
    "\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n",
    "\n",
    "Dataset is divided into 5 batches with the following naming convention 'data_batch_1', 'data_batch_2' and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "DATA_URL = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "TARG_TZ_FILEPATH = \"./cifar-10-python.tar.gz\"\n",
    "CIFAR10_FILES_FOLDER = './cifar-10-batches-py/'\n",
    "\n",
    "TRAIN_BATCH_FILES = [\n",
    "    \"data_batch_1\",\n",
    "    \"data_batch_2\",\n",
    "    \"data_batch_3\",\n",
    "    \"data_batch_4\",\n",
    "    \"data_batch_5\"\n",
    "]\n",
    "\n",
    "TEST_BATCH_FILE = \"test_batch\"\n",
    "\n",
    "LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "MAX_PIXEL_VALUE = 255\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "CHANNELS = 3\n",
    "\n",
    "DATA_I = 0\n",
    "LABELS_I = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not os.path.isfile(TARG_TZ_FILEPATH):\n",
    "    with DLProgress(unit=\"B\", unit_scale=True, miniters=1, desc=\"CIFAR-10\") as pbar:\n",
    "        urlretrieve(DATA_URL, TARG_TZ_FILEPATH, pbar.hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exctracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(CIFAR10_FILES_FOLDER):\n",
    "    with tarfile.open(TARG_TZ_FILEPATH) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = list()\n",
    "\n",
    "for batch_file in BATCH_FILES: \n",
    "    with open(CIFAR10_FILES_FOLDER + batch_file, mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "        # array of 10000 * 1 length\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        # all channels in single 10000 * 3072 length array\n",
    "        batch_data = batch['data']\n",
    "        \n",
    "        # reshaping to 10000 * 3 * 32 * 32\n",
    "        data = batch_data.reshape((len(batch_data), CHANNELS, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        \n",
    "        # fix indexing\n",
    "        data = data.transpose(0, 2, 3, 1)\n",
    "  \n",
    "        train_batches.append((data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = None\n",
    "\n",
    "with open(CIFAR10_FILES_FOLDER + TEST_BATCH_FILE, mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "        # array of 10000 * 1 length\n",
    "        labels = batch['labels']\n",
    "        \n",
    "         # all channels in single 10000 * 3072 length array\n",
    "        batch_data = batch['data']\n",
    "        \n",
    "        # reshaping to 10000 * 3 * 32 * 32\n",
    "        data = batch_data.reshape((len(batch_data), CHANNELS, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        \n",
    "        # fix indexing\n",
    "        data = data.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        test_batch = (data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present extracted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def present_batch(batch, batch_index):\n",
    "    features, labels = batch \n",
    "    print(\"Batch no.\" + str(batch_index))\n",
    "    print(\"    - Samples in batch: \" + str(len(features)))\n",
    "    print(\"    - Labels num: \" + str(dict(zip(*np.unique(labels, return_counts=True)))))\n",
    "    \n",
    "def present_sample(batch, sample_id):\n",
    "    features, labels = batch \n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print(\"Sample no.\" + str(sample_id))\n",
    "    print(\"    - Min Value: {} Max Value: {}\".format(sample_image.min(), sample_image.max()))\n",
    "    print(\"    - Shape: {}\".format(sample_image.shape))\n",
    "    print(\"    - Label - Label Id: {} Name: {}\".format(sample_label, LABELS[sample_label]))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch no.0\n",
      "    - Samples in batch: 10000\n",
      "    - Labels num: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "Batch no.1\n",
      "    - Samples in batch: 10000\n",
      "    - Labels num: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "Batch no.2\n",
      "    - Samples in batch: 10000\n",
      "    - Labels num: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "Batch no.3\n",
      "    - Samples in batch: 10000\n",
      "    - Labels num: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "Batch no.4\n",
      "    - Samples in batch: 10000\n",
      "    - Labels num: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n"
     ]
    }
   ],
   "source": [
    "for index, batch in enumerate(train_batches):\n",
    "    present_batch(batch, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample no.7164\n",
      "    - Min Value: 26 Max Value: 246\n",
      "    - Shape: (32, 32, 3)\n",
      "    - Label - Label Id: 5 Name: dog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/5nVlbAiE/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e74c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "present_sample(train_batches[0], 7164)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list()\n",
    "for batch in train_batches:\n",
    "    for data, label in zip(batch[DATA_I], batch[LABELS_I]):\n",
    "        train_data.append((data, label))\n",
    "    \n",
    "test_data = list()\n",
    "for data, label in zip(test_batch[DATA_I], test_batch[LABELS_I]):\n",
    "    test_data.append((data, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 50000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples: \" + str(len(train_data)))\n",
    "print(\"Test samples: \" + str(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data / MAX_PIXEL_VALUE\n",
    "\n",
    "def ohe_label(label):\n",
    "    labels_num = len(LABELS)\n",
    "  \n",
    "    encoding_array = np.zeros([labels_num])  \n",
    "    encoding_array[label] = 1\n",
    "        \n",
    "    return encoding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm = [(normalize(data[DATA_I]), ohe_label(data[LABELS_I])) for data in train_data]\n",
    "test_data_norm = [(normalize(data[DATA_I]), ohe_label(data[LABELS_I])) for data in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample no.7124\n",
      "    - Min Value: 0.0 Max Value: 1.0\n",
      "    - Label: [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "sample_to_inspect = 7124\n",
    "sample = train_data_norm[sample_to_inspect]\n",
    "print(\"Sample no.\" + str(sample_to_inspect))\n",
    "print(\"    - Min Value: {} Max Value: {}\".format(sample[DATA_I].min(), sample[DATA_I].max()))\n",
    "print(\"    - Label: \" + str(sample[LABELS_I]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net_image_input(image_width, image_height, channels):\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_width, image_height, channels], name='inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net_label_input(n_classes):\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net_keep_prob_input():\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    \"\"\"\n",
    "    Preprocess Training and Validation Data\n",
    "    \"\"\"\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        validation_count = int(len(features) * 0.1)\n",
    "\n",
    "        # Prprocess and save a batch of training data\n",
    "        _preprocess_and_save(\n",
    "            normalize,\n",
    "            one_hot_encode,\n",
    "            features[:-validation_count],\n",
    "            labels[:-validation_count],\n",
    "            'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # Use a portion of training batch for validation\n",
    "        valid_features.extend(features[-validation_count:])\n",
    "        valid_labels.extend(labels[-validation_count:])\n",
    "\n",
    "    # Preprocess and Save all validation data\n",
    "    _preprocess_and_save(\n",
    "        normalize,\n",
    "        one_hot_encode,\n",
    "        np.array(valid_features),\n",
    "        np.array(valid_labels),\n",
    "        'preprocess_validation.p')\n",
    "\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # load the test data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all test data\n",
    "    _preprocess_and_save(\n",
    "        normalize,\n",
    "        one_hot_encode,\n",
    "        np.array(test_features),\n",
    "        np.array(test_labels),\n",
    "        'preprocess_test.p')\n",
    "\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)\n",
    "\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "\n",
    "        axies[image_i][0].imshow(feature)\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
