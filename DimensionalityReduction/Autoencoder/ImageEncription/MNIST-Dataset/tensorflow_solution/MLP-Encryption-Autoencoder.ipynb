{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.examples.tutorials.mnist as mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: http://yann.lecun.com/exdb/mnist/\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading files\n",
    "Data is already preprocessed, shuffled and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tensorflow/examples/tutorials/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting tensorflow/examples/tutorials/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting tensorflow/examples/tutorials/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting tensorflow/examples/tutorials/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset = mnist.input_data.read_data_sets('tensorflow/examples/tutorials/mnist', one_hot=True, validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_for_autoencoder = mnist_dataset.train.images\n",
    "images_for_autoencoder_labels = mnist_dataset.train.labels.astype(np.float32)\n",
    "\n",
    "test_images = mnist_dataset.test.images\n",
    "test_images_labels = mnist_dataset.test.labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGES_NUM = images_for_autoencoder.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_digit(trainX, trainY, index):\n",
    "    image = trainX[index].reshape([IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "    label = trainY[index]\n",
    "    plt.title(\"Training data, index: {},  Label: {}\".format(index, label))\n",
    "    plt.imshow(image, cmap=\"gray_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (60000, 784)\n",
      "Labels: (60000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEICAYAAADsh6tqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUjEMLUlSMQwtSVIxDC1JUjH+P3fdVkwTjmVeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b396438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Images: \" + str(images_for_autoencoder.shape))\n",
    "print(\"Labels: \" + str(images_for_autoencoder_labels.shape))\n",
    "show_digit(images_for_autoencoder, images_for_autoencoder_labels, np.random.randint(1, IMAGES_NUM + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset tensorflow graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, [None, IMAGE_WIDTH * IMAGE_HEIGHT], \"inputs\")\n",
    "targets_ = tf.placeholder(tf.float32, [None, IMAGE_WIDTH * IMAGE_HEIGHT], \"targets\")\n",
    "learning_rate_ = tf.placeholder(tf.float32, None, name=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28 * 28 MNIST image will be encoded into 'encoding_size' numbers\n",
    "encoder_logits = tf.layers.dense(inputs_, encoding_size, activation=None)\n",
    "encoded = tf.nn.relu(encoder_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'encoding_size' numbers will be decoded into normalized image\n",
    "decoder_logits = tf.layers.dense(encoded, IMAGE_WIDTH * IMAGE_HEIGHT, activation=None)\n",
    "decoded = activation=tf.nn.sigmoid(decoder_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_value = tf.nn.sigmoid_cross_entropy_with_logits(logits=decoder_logits, labels=targets_)\n",
    "cost_value = tf.reduce_mean(loss_value)\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 48\n",
    "num_batches = IMAGES_NUM // batch_size\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_mini_batches(data, labels, batch_size):\n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    all_batches = list()\n",
    "    for i in range(0, len(data)):\n",
    "        all_batches.append((data[i], labels[i]))\n",
    "    random.shuffle(all_batches)\n",
    "        \n",
    "    mini_batches = list()\n",
    "    while len(all_batches) >= batch_size:\n",
    "        \n",
    "        data_batch = list()\n",
    "        labels_batch = list()\n",
    "        for j in range(0, batch_size):\n",
    "            data, labels = all_batches.pop()\n",
    "            data_batch.append(data)\n",
    "            labels_batch.append(labels)\n",
    "            \n",
    "        mini_batches.append((np.array(data_batch), np.array(labels_batch)))\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.6915\n",
      "Epoch: 1/30... Training loss: 0.6889\n",
      "Epoch: 1/30... Training loss: 0.6861\n",
      "Epoch: 1/30... Training loss: 0.6831\n",
      "Epoch: 1/30... Training loss: 0.6797\n",
      "Epoch: 1/30... Training loss: 0.6757\n",
      "Epoch: 1/30... Training loss: 0.6723\n",
      "Epoch: 1/30... Training loss: 0.6675\n",
      "Epoch: 1/30... Training loss: 0.6626\n",
      "Epoch: 1/30... Training loss: 0.6559\n",
      "Epoch: 1/30... Training loss: 0.6493\n",
      "Epoch: 1/30... Training loss: 0.6427\n",
      "Epoch: 1/30... Training loss: 0.6325\n",
      "Epoch: 1/30... Training loss: 0.6235\n",
      "Epoch: 1/30... Training loss: 0.6146\n",
      "Epoch: 1/30... Training loss: 0.6076\n",
      "Epoch: 1/30... Training loss: 0.5938\n",
      "Epoch: 1/30... Training loss: 0.5855\n",
      "Epoch: 1/30... Training loss: 0.5768\n",
      "Epoch: 1/30... Training loss: 0.5591\n",
      "Epoch: 1/30... Training loss: 0.5464\n",
      "Epoch: 1/30... Training loss: 0.5406\n",
      "Epoch: 1/30... Training loss: 0.5218\n",
      "Epoch: 1/30... Training loss: 0.5087\n",
      "Epoch: 1/30... Training loss: 0.4983\n",
      "Epoch: 1/30... Training loss: 0.4808\n",
      "Epoch: 1/30... Training loss: 0.4725\n",
      "Epoch: 1/30... Training loss: 0.4515\n",
      "Epoch: 1/30... Training loss: 0.4520\n",
      "Epoch: 1/30... Training loss: 0.4319\n",
      "Epoch: 1/30... Training loss: 0.4123\n",
      "Epoch: 1/30... Training loss: 0.4085\n",
      "Epoch: 1/30... Training loss: 0.4050\n",
      "Epoch: 1/30... Training loss: 0.3834\n",
      "Epoch: 1/30... Training loss: 0.3810\n",
      "Epoch: 1/30... Training loss: 0.3687\n",
      "Epoch: 1/30... Training loss: 0.3592\n",
      "Epoch: 1/30... Training loss: 0.3549\n",
      "Epoch: 1/30... Training loss: 0.3430\n",
      "Epoch: 1/30... Training loss: 0.3515\n",
      "Epoch: 1/30... Training loss: 0.3588\n",
      "Epoch: 1/30... Training loss: 0.3434\n",
      "Epoch: 1/30... Training loss: 0.3231\n",
      "Epoch: 1/30... Training loss: 0.3530\n",
      "Epoch: 1/30... Training loss: 0.3204\n",
      "Epoch: 1/30... Training loss: 0.3067\n",
      "Epoch: 1/30... Training loss: 0.3036\n",
      "Epoch: 1/30... Training loss: 0.2964\n",
      "Epoch: 1/30... Training loss: 0.3007\n",
      "Epoch: 1/30... Training loss: 0.2939\n",
      "Epoch: 1/30... Training loss: 0.3035\n",
      "Epoch: 1/30... Training loss: 0.3052\n",
      "Epoch: 1/30... Training loss: 0.2917\n",
      "Epoch: 1/30... Training loss: 0.2880\n",
      "Epoch: 1/30... Training loss: 0.2914\n",
      "Epoch: 1/30... Training loss: 0.2955\n",
      "Epoch: 1/30... Training loss: 0.3024\n",
      "Epoch: 1/30... Training loss: 0.2950\n",
      "Epoch: 1/30... Training loss: 0.2851\n",
      "Epoch: 1/30... Training loss: 0.2890\n",
      "Epoch: 1/30... Training loss: 0.2944\n",
      "Epoch: 1/30... Training loss: 0.2765\n",
      "Epoch: 1/30... Training loss: 0.2853\n",
      "Epoch: 1/30... Training loss: 0.2857\n",
      "Epoch: 1/30... Training loss: 0.2863\n",
      "Epoch: 1/30... Training loss: 0.2866\n",
      "Epoch: 1/30... Training loss: 0.2775\n",
      "Epoch: 1/30... Training loss: 0.2976\n",
      "Epoch: 1/30... Training loss: 0.2758\n",
      "Epoch: 1/30... Training loss: 0.2786\n",
      "Epoch: 1/30... Training loss: 0.2836\n",
      "Epoch: 1/30... Training loss: 0.2883\n",
      "Epoch: 1/30... Training loss: 0.2860\n",
      "Epoch: 1/30... Training loss: 0.2846\n",
      "Epoch: 1/30... Training loss: 0.2751\n",
      "Epoch: 1/30... Training loss: 0.2821\n",
      "Epoch: 1/30... Training loss: 0.2787\n",
      "Epoch: 1/30... Training loss: 0.2813\n",
      "Epoch: 1/30... Training loss: 0.2797\n",
      "Epoch: 1/30... Training loss: 0.2771\n",
      "Epoch: 1/30... Training loss: 0.2732\n",
      "Epoch: 1/30... Training loss: 0.2701\n",
      "Epoch: 1/30... Training loss: 0.2553\n",
      "Epoch: 1/30... Training loss: 0.2733\n",
      "Epoch: 1/30... Training loss: 0.2740\n",
      "Epoch: 1/30... Training loss: 0.2817\n",
      "Epoch: 1/30... Training loss: 0.2656\n",
      "Epoch: 1/30... Training loss: 0.2672\n",
      "Epoch: 1/30... Training loss: 0.2639\n",
      "Epoch: 1/30... Training loss: 0.2777\n",
      "Epoch: 1/30... Training loss: 0.2683\n",
      "Epoch: 1/30... Training loss: 0.2861\n",
      "Epoch: 1/30... Training loss: 0.2592\n",
      "Epoch: 1/30... Training loss: 0.2697\n",
      "Epoch: 1/30... Training loss: 0.2693\n",
      "Epoch: 1/30... Training loss: 0.2748\n",
      "Epoch: 1/30... Training loss: 0.2668\n",
      "Epoch: 1/30... Training loss: 0.2794\n",
      "Epoch: 1/30... Training loss: 0.2633\n",
      "Epoch: 1/30... Training loss: 0.2617\n",
      "Epoch: 1/30... Training loss: 0.2567\n",
      "Epoch: 1/30... Training loss: 0.2742\n",
      "Epoch: 1/30... Training loss: 0.2606\n",
      "Epoch: 1/30... Training loss: 0.2705\n",
      "Epoch: 1/30... Training loss: 0.2595\n",
      "Epoch: 1/30... Training loss: 0.2657\n",
      "Epoch: 1/30... Training loss: 0.2537\n",
      "Epoch: 1/30... Training loss: 0.2586\n",
      "Epoch: 1/30... Training loss: 0.2498\n",
      "Epoch: 1/30... Training loss: 0.2642\n",
      "Epoch: 1/30... Training loss: 0.2671\n",
      "Epoch: 1/30... Training loss: 0.2597\n",
      "Epoch: 1/30... Training loss: 0.2546\n",
      "Epoch: 1/30... Training loss: 0.2548\n",
      "Epoch: 1/30... Training loss: 0.2694\n",
      "Epoch: 1/30... Training loss: 0.2649\n",
      "Epoch: 1/30... Training loss: 0.2493\n",
      "Epoch: 1/30... Training loss: 0.2535\n",
      "Epoch: 1/30... Training loss: 0.2649\n",
      "Epoch: 1/30... Training loss: 0.2561\n",
      "Epoch: 1/30... Training loss: 0.2576\n",
      "Epoch: 1/30... Training loss: 0.2553\n",
      "Epoch: 1/30... Training loss: 0.2559\n",
      "Epoch: 1/30... Training loss: 0.2654\n",
      "Epoch: 1/30... Training loss: 0.2510\n",
      "Epoch: 1/30... Training loss: 0.2360\n",
      "Epoch: 1/30... Training loss: 0.2395\n",
      "Epoch: 1/30... Training loss: 0.2457\n",
      "Epoch: 1/30... Training loss: 0.2467\n",
      "Epoch: 1/30... Training loss: 0.2371\n",
      "Epoch: 1/30... Training loss: 0.2404\n",
      "Epoch: 1/30... Training loss: 0.2432\n",
      "Epoch: 1/30... Training loss: 0.2664\n",
      "Epoch: 1/30... Training loss: 0.2404\n",
      "Epoch: 1/30... Training loss: 0.2530\n",
      "Epoch: 1/30... Training loss: 0.2423\n",
      "Epoch: 1/30... Training loss: 0.2411\n",
      "Epoch: 1/30... Training loss: 0.2523\n",
      "Epoch: 1/30... Training loss: 0.2363\n",
      "Epoch: 1/30... Training loss: 0.2440\n",
      "Epoch: 1/30... Training loss: 0.2449\n",
      "Epoch: 1/30... Training loss: 0.2479\n",
      "Epoch: 1/30... Training loss: 0.2384\n",
      "Epoch: 1/30... Training loss: 0.2524\n",
      "Epoch: 1/30... Training loss: 0.2470\n",
      "Epoch: 1/30... Training loss: 0.2363\n",
      "Epoch: 1/30... Training loss: 0.2560\n",
      "Epoch: 1/30... Training loss: 0.2553\n",
      "Epoch: 1/30... Training loss: 0.2375\n",
      "Epoch: 1/30... Training loss: 0.2508\n",
      "Epoch: 1/30... Training loss: 0.2389\n",
      "Epoch: 1/30... Training loss: 0.2405\n",
      "Epoch: 1/30... Training loss: 0.2375\n",
      "Epoch: 1/30... Training loss: 0.2311\n",
      "Epoch: 1/30... Training loss: 0.2380\n",
      "Epoch: 1/30... Training loss: 0.2351\n",
      "Epoch: 1/30... Training loss: 0.2385\n",
      "Epoch: 1/30... Training loss: 0.2432\n",
      "Epoch: 1/30... Training loss: 0.2460\n",
      "Epoch: 1/30... Training loss: 0.2463\n",
      "Epoch: 1/30... Training loss: 0.2411\n",
      "Epoch: 1/30... Training loss: 0.2549\n",
      "Epoch: 1/30... Training loss: 0.2398\n",
      "Epoch: 1/30... Training loss: 0.2431\n",
      "Epoch: 1/30... Training loss: 0.2438\n",
      "Epoch: 1/30... Training loss: 0.2325\n",
      "Epoch: 1/30... Training loss: 0.2198\n",
      "Epoch: 1/30... Training loss: 0.2312\n",
      "Epoch: 1/30... Training loss: 0.2335\n",
      "Epoch: 1/30... Training loss: 0.2510\n",
      "Epoch: 1/30... Training loss: 0.2380\n",
      "Epoch: 1/30... Training loss: 0.2307\n",
      "Epoch: 1/30... Training loss: 0.2363\n",
      "Epoch: 1/30... Training loss: 0.2278\n",
      "Epoch: 1/30... Training loss: 0.2287\n",
      "Epoch: 1/30... Training loss: 0.2342\n",
      "Epoch: 1/30... Training loss: 0.2281\n",
      "Epoch: 1/30... Training loss: 0.2293\n",
      "Epoch: 1/30... Training loss: 0.2315\n",
      "Epoch: 1/30... Training loss: 0.2270\n",
      "Epoch: 1/30... Training loss: 0.2258\n",
      "Epoch: 1/30... Training loss: 0.2393\n",
      "Epoch: 1/30... Training loss: 0.2258\n",
      "Epoch: 1/30... Training loss: 0.2267\n",
      "Epoch: 1/30... Training loss: 0.2311\n",
      "Epoch: 1/30... Training loss: 0.2252\n",
      "Epoch: 1/30... Training loss: 0.2351\n",
      "Epoch: 1/30... Training loss: 0.2224\n",
      "Epoch: 1/30... Training loss: 0.2278\n",
      "Epoch: 1/30... Training loss: 0.2260\n",
      "Epoch: 1/30... Training loss: 0.2400\n",
      "Epoch: 1/30... Training loss: 0.2375\n",
      "Epoch: 1/30... Training loss: 0.2315\n",
      "Epoch: 1/30... Training loss: 0.2221\n",
      "Epoch: 1/30... Training loss: 0.2261\n",
      "Epoch: 1/30... Training loss: 0.2181\n",
      "Epoch: 1/30... Training loss: 0.2289\n",
      "Epoch: 1/30... Training loss: 0.2300\n",
      "Epoch: 1/30... Training loss: 0.2220\n",
      "Epoch: 1/30... Training loss: 0.2225\n",
      "Epoch: 1/30... Training loss: 0.2167\n",
      "Epoch: 1/30... Training loss: 0.2218\n",
      "Epoch: 1/30... Training loss: 0.2305\n",
      "Epoch: 1/30... Training loss: 0.2151\n",
      "Epoch: 1/30... Training loss: 0.2266\n",
      "Epoch: 1/30... Training loss: 0.2259\n",
      "Epoch: 1/30... Training loss: 0.2239\n",
      "Epoch: 1/30... Training loss: 0.2169\n",
      "Epoch: 1/30... Training loss: 0.2070\n",
      "Epoch: 1/30... Training loss: 0.2160\n",
      "Epoch: 1/30... Training loss: 0.2175\n",
      "Epoch: 1/30... Training loss: 0.2200\n",
      "Epoch: 1/30... Training loss: 0.2264\n",
      "Epoch: 1/30... Training loss: 0.2181\n",
      "Epoch: 1/30... Training loss: 0.2242\n",
      "Epoch: 1/30... Training loss: 0.2148\n",
      "Epoch: 1/30... Training loss: 0.2273\n",
      "Epoch: 1/30... Training loss: 0.2149\n",
      "Epoch: 1/30... Training loss: 0.2135\n",
      "Epoch: 1/30... Training loss: 0.2219\n",
      "Epoch: 1/30... Training loss: 0.2276\n",
      "Epoch: 1/30... Training loss: 0.2214\n",
      "Epoch: 1/30... Training loss: 0.2071\n",
      "Epoch: 1/30... Training loss: 0.2026\n",
      "Epoch: 1/30... Training loss: 0.2141\n",
      "Epoch: 1/30... Training loss: 0.2159\n",
      "Epoch: 1/30... Training loss: 0.2065\n",
      "Epoch: 1/30... Training loss: 0.2020\n",
      "Epoch: 1/30... Training loss: 0.2229\n",
      "Epoch: 1/30... Training loss: 0.2178\n",
      "Epoch: 1/30... Training loss: 0.2215\n",
      "Epoch: 1/30... Training loss: 0.2214\n",
      "Epoch: 1/30... Training loss: 0.2105\n",
      "Epoch: 1/30... Training loss: 0.2064\n",
      "Epoch: 1/30... Training loss: 0.2135\n",
      "Epoch: 1/30... Training loss: 0.2242\n",
      "Epoch: 1/30... Training loss: 0.2094\n",
      "Epoch: 1/30... Training loss: 0.2105\n",
      "Epoch: 1/30... Training loss: 0.2225\n",
      "Epoch: 1/30... Training loss: 0.2167\n",
      "Epoch: 1/30... Training loss: 0.2031\n",
      "Epoch: 1/30... Training loss: 0.2074\n",
      "Epoch: 1/30... Training loss: 0.2056\n",
      "Epoch: 1/30... Training loss: 0.2124\n",
      "Epoch: 1/30... Training loss: 0.2334\n",
      "Epoch: 1/30... Training loss: 0.2064\n",
      "Epoch: 1/30... Training loss: 0.1994\n",
      "Epoch: 1/30... Training loss: 0.2101\n",
      "Epoch: 1/30... Training loss: 0.2075\n",
      "Epoch: 1/30... Training loss: 0.2076\n",
      "Epoch: 1/30... Training loss: 0.2131\n",
      "Epoch: 1/30... Training loss: 0.2143\n",
      "Epoch: 1/30... Training loss: 0.2015\n",
      "Epoch: 1/30... Training loss: 0.2062\n",
      "Epoch: 1/30... Training loss: 0.2040\n",
      "Epoch: 1/30... Training loss: 0.2047\n",
      "Epoch: 1/30... Training loss: 0.2121\n",
      "Epoch: 1/30... Training loss: 0.2073\n",
      "Epoch: 1/30... Training loss: 0.1992\n",
      "Epoch: 1/30... Training loss: 0.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.2144\n",
      "Epoch: 1/30... Training loss: 0.2043\n",
      "Epoch: 1/30... Training loss: 0.2117\n",
      "Epoch: 1/30... Training loss: 0.2033\n",
      "Epoch: 1/30... Training loss: 0.2132\n",
      "Epoch: 1/30... Training loss: 0.2078\n",
      "Epoch: 1/30... Training loss: 0.2094\n",
      "Epoch: 1/30... Training loss: 0.2142\n",
      "Epoch: 1/30... Training loss: 0.2006\n",
      "Epoch: 1/30... Training loss: 0.2014\n",
      "Epoch: 1/30... Training loss: 0.2031\n",
      "Epoch: 1/30... Training loss: 0.2030\n",
      "Epoch: 1/30... Training loss: 0.2102\n",
      "Epoch: 1/30... Training loss: 0.2152\n",
      "Epoch: 1/30... Training loss: 0.2129\n",
      "Epoch: 1/30... Training loss: 0.2139\n",
      "Epoch: 1/30... Training loss: 0.2025\n",
      "Epoch: 1/30... Training loss: 0.2083\n",
      "Epoch: 1/30... Training loss: 0.2058\n",
      "Epoch: 1/30... Training loss: 0.2084\n",
      "Epoch: 1/30... Training loss: 0.2058\n",
      "Epoch: 1/30... Training loss: 0.1997\n",
      "Epoch: 1/30... Training loss: 0.2166\n",
      "Epoch: 1/30... Training loss: 0.1962\n",
      "Epoch: 1/30... Training loss: 0.1996\n",
      "Epoch: 1/30... Training loss: 0.1964\n",
      "Epoch: 1/30... Training loss: 0.2065\n",
      "Epoch: 1/30... Training loss: 0.1978\n",
      "Epoch: 1/30... Training loss: 0.1960\n",
      "Epoch: 1/30... Training loss: 0.1976\n",
      "Epoch: 1/30... Training loss: 0.2097\n",
      "Epoch: 1/30... Training loss: 0.1813\n",
      "Epoch: 1/30... Training loss: 0.1981\n",
      "Epoch: 1/30... Training loss: 0.1881\n",
      "Epoch: 1/30... Training loss: 0.1981\n",
      "Epoch: 1/30... Training loss: 0.1966\n",
      "Epoch: 1/30... Training loss: 0.1905\n",
      "Epoch: 1/30... Training loss: 0.1915\n",
      "Epoch: 1/30... Training loss: 0.1805\n",
      "Epoch: 1/30... Training loss: 0.2039\n",
      "Epoch: 1/30... Training loss: 0.2039\n",
      "Epoch: 1/30... Training loss: 0.1956\n",
      "Epoch: 1/30... Training loss: 0.1802\n",
      "Epoch: 1/30... Training loss: 0.2045\n",
      "Epoch: 1/30... Training loss: 0.1970\n",
      "Epoch: 1/30... Training loss: 0.2015\n",
      "Epoch: 1/30... Training loss: 0.2018\n",
      "Epoch: 1/30... Training loss: 0.1881\n",
      "Epoch: 1/30... Training loss: 0.2111\n",
      "Epoch: 1/30... Training loss: 0.1963\n",
      "Epoch: 1/30... Training loss: 0.2189\n",
      "Epoch: 1/30... Training loss: 0.2020\n",
      "Epoch: 1/30... Training loss: 0.2092\n",
      "Epoch: 1/30... Training loss: 0.1955\n",
      "Epoch: 1/30... Training loss: 0.2042\n",
      "Epoch: 1/30... Training loss: 0.1956\n",
      "Epoch: 1/30... Training loss: 0.2035\n",
      "Epoch: 1/30... Training loss: 0.1906\n",
      "Epoch: 1/30... Training loss: 0.1992\n",
      "Epoch: 1/30... Training loss: 0.2063\n",
      "Epoch: 1/30... Training loss: 0.1937\n",
      "Epoch: 1/30... Training loss: 0.1959\n",
      "Epoch: 1/30... Training loss: 0.1946\n",
      "Epoch: 1/30... Training loss: 0.1955\n",
      "Epoch: 1/30... Training loss: 0.1960\n",
      "Epoch: 1/30... Training loss: 0.1911\n",
      "Epoch: 1/30... Training loss: 0.1911\n",
      "Epoch: 1/30... Training loss: 0.1950\n",
      "Epoch: 1/30... Training loss: 0.1919\n",
      "Epoch: 1/30... Training loss: 0.2086\n",
      "Epoch: 1/30... Training loss: 0.2058\n",
      "Epoch: 1/30... Training loss: 0.1907\n",
      "Epoch: 1/30... Training loss: 0.1818\n",
      "Epoch: 1/30... Training loss: 0.2055\n",
      "Epoch: 1/30... Training loss: 0.1947\n",
      "Epoch: 1/30... Training loss: 0.1995\n",
      "Epoch: 1/30... Training loss: 0.2008\n",
      "Epoch: 1/30... Training loss: 0.1857\n",
      "Epoch: 1/30... Training loss: 0.1908\n",
      "Epoch: 1/30... Training loss: 0.1891\n",
      "Epoch: 1/30... Training loss: 0.1923\n",
      "Epoch: 1/30... Training loss: 0.1980\n",
      "Epoch: 1/30... Training loss: 0.1831\n",
      "Epoch: 1/30... Training loss: 0.1887\n",
      "Epoch: 1/30... Training loss: 0.1873\n",
      "Epoch: 1/30... Training loss: 0.1906\n",
      "Epoch: 1/30... Training loss: 0.1900\n",
      "Epoch: 1/30... Training loss: 0.1940\n",
      "Epoch: 1/30... Training loss: 0.1824\n",
      "Epoch: 1/30... Training loss: 0.1869\n",
      "Epoch: 1/30... Training loss: 0.1957\n",
      "Epoch: 1/30... Training loss: 0.1784\n",
      "Epoch: 1/30... Training loss: 0.1793\n",
      "Epoch: 1/30... Training loss: 0.1805\n",
      "Epoch: 1/30... Training loss: 0.2062\n",
      "Epoch: 1/30... Training loss: 0.1841\n",
      "Epoch: 1/30... Training loss: 0.1941\n",
      "Epoch: 1/30... Training loss: 0.1866\n",
      "Epoch: 1/30... Training loss: 0.1775\n",
      "Epoch: 1/30... Training loss: 0.1965\n",
      "Epoch: 1/30... Training loss: 0.1879\n",
      "Epoch: 1/30... Training loss: 0.1821\n",
      "Epoch: 1/30... Training loss: 0.1929\n",
      "Epoch: 1/30... Training loss: 0.1973\n",
      "Epoch: 1/30... Training loss: 0.1930\n",
      "Epoch: 1/30... Training loss: 0.1965\n",
      "Epoch: 1/30... Training loss: 0.1856\n",
      "Epoch: 1/30... Training loss: 0.1811\n",
      "Epoch: 1/30... Training loss: 0.1916\n",
      "Epoch: 1/30... Training loss: 0.1847\n",
      "Epoch: 1/30... Training loss: 0.1703\n",
      "Epoch: 1/30... Training loss: 0.1878\n",
      "Epoch: 1/30... Training loss: 0.1824\n",
      "Epoch: 1/30... Training loss: 0.1956\n",
      "Epoch: 1/30... Training loss: 0.1912\n",
      "Epoch: 1/30... Training loss: 0.2034\n",
      "Epoch: 1/30... Training loss: 0.1865\n",
      "Epoch: 1/30... Training loss: 0.1901\n",
      "Epoch: 1/30... Training loss: 0.1853\n",
      "Epoch: 1/30... Training loss: 0.1966\n",
      "Epoch: 1/30... Training loss: 0.1802\n",
      "Epoch: 1/30... Training loss: 0.1804\n",
      "Epoch: 1/30... Training loss: 0.1824\n",
      "Epoch: 1/30... Training loss: 0.1793\n",
      "Epoch: 1/30... Training loss: 0.1838\n",
      "Epoch: 1/30... Training loss: 0.1826\n",
      "Epoch: 1/30... Training loss: 0.1865\n",
      "Epoch: 1/30... Training loss: 0.2032\n",
      "Epoch: 1/30... Training loss: 0.1972\n",
      "Epoch: 1/30... Training loss: 0.1893\n",
      "Epoch: 1/30... Training loss: 0.1967\n",
      "Epoch: 1/30... Training loss: 0.1924\n",
      "Epoch: 1/30... Training loss: 0.1918\n",
      "Epoch: 1/30... Training loss: 0.1969\n",
      "Epoch: 1/30... Training loss: 0.1755\n",
      "Epoch: 1/30... Training loss: 0.1921\n",
      "Epoch: 1/30... Training loss: 0.1789\n",
      "Epoch: 1/30... Training loss: 0.1779\n",
      "Epoch: 1/30... Training loss: 0.1852\n",
      "Epoch: 1/30... Training loss: 0.1776\n",
      "Epoch: 1/30... Training loss: 0.1801\n",
      "Epoch: 1/30... Training loss: 0.1843\n",
      "Epoch: 1/30... Training loss: 0.1929\n",
      "Epoch: 1/30... Training loss: 0.1835\n",
      "Epoch: 1/30... Training loss: 0.1999\n",
      "Epoch: 1/30... Training loss: 0.1828\n",
      "Epoch: 1/30... Training loss: 0.1888\n",
      "Epoch: 1/30... Training loss: 0.1894\n",
      "Epoch: 1/30... Training loss: 0.1813\n",
      "Epoch: 1/30... Training loss: 0.1810\n",
      "Epoch: 1/30... Training loss: 0.1767\n",
      "Epoch: 1/30... Training loss: 0.1692\n",
      "Epoch: 1/30... Training loss: 0.1753\n",
      "Epoch: 1/30... Training loss: 0.1855\n",
      "Epoch: 1/30... Training loss: 0.1785\n",
      "Epoch: 1/30... Training loss: 0.1704\n",
      "Epoch: 1/30... Training loss: 0.1826\n",
      "Epoch: 1/30... Training loss: 0.1749\n",
      "Epoch: 1/30... Training loss: 0.1867\n",
      "Epoch: 1/30... Training loss: 0.1841\n",
      "Epoch: 1/30... Training loss: 0.1880\n",
      "Epoch: 1/30... Training loss: 0.1799\n",
      "Epoch: 1/30... Training loss: 0.1782\n",
      "Epoch: 1/30... Training loss: 0.1818\n",
      "Epoch: 1/30... Training loss: 0.1703\n",
      "Epoch: 1/30... Training loss: 0.1783\n",
      "Epoch: 1/30... Training loss: 0.1903\n",
      "Epoch: 1/30... Training loss: 0.1802\n",
      "Epoch: 1/30... Training loss: 0.1723\n",
      "Epoch: 1/30... Training loss: 0.1785\n",
      "Epoch: 1/30... Training loss: 0.1660\n",
      "Epoch: 1/30... Training loss: 0.1878\n",
      "Epoch: 1/30... Training loss: 0.1872\n",
      "Epoch: 1/30... Training loss: 0.1977\n",
      "Epoch: 1/30... Training loss: 0.1698\n",
      "Epoch: 1/30... Training loss: 0.1806\n",
      "Epoch: 1/30... Training loss: 0.1884\n",
      "Epoch: 1/30... Training loss: 0.1774\n",
      "Epoch: 1/30... Training loss: 0.1704\n",
      "Epoch: 1/30... Training loss: 0.1838\n",
      "Epoch: 1/30... Training loss: 0.1833\n",
      "Epoch: 1/30... Training loss: 0.1710\n",
      "Epoch: 1/30... Training loss: 0.1949\n",
      "Epoch: 1/30... Training loss: 0.1748\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1734\n",
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1677\n",
      "Epoch: 1/30... Training loss: 0.1631\n",
      "Epoch: 1/30... Training loss: 0.1829\n",
      "Epoch: 1/30... Training loss: 0.1698\n",
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1924\n",
      "Epoch: 1/30... Training loss: 0.1885\n",
      "Epoch: 1/30... Training loss: 0.1708\n",
      "Epoch: 1/30... Training loss: 0.1746\n",
      "Epoch: 1/30... Training loss: 0.1712\n",
      "Epoch: 1/30... Training loss: 0.1898\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1783\n",
      "Epoch: 1/30... Training loss: 0.1818\n",
      "Epoch: 1/30... Training loss: 0.1780\n",
      "Epoch: 1/30... Training loss: 0.1769\n",
      "Epoch: 1/30... Training loss: 0.1737\n",
      "Epoch: 1/30... Training loss: 0.1675\n",
      "Epoch: 1/30... Training loss: 0.1933\n",
      "Epoch: 1/30... Training loss: 0.1738\n",
      "Epoch: 1/30... Training loss: 0.1769\n",
      "Epoch: 1/30... Training loss: 0.1727\n",
      "Epoch: 1/30... Training loss: 0.1764\n",
      "Epoch: 1/30... Training loss: 0.1837\n",
      "Epoch: 1/30... Training loss: 0.1888\n",
      "Epoch: 1/30... Training loss: 0.1715\n",
      "Epoch: 1/30... Training loss: 0.1753\n",
      "Epoch: 1/30... Training loss: 0.1710\n",
      "Epoch: 1/30... Training loss: 0.1770\n",
      "Epoch: 1/30... Training loss: 0.1690\n",
      "Epoch: 1/30... Training loss: 0.1748\n",
      "Epoch: 1/30... Training loss: 0.1673\n",
      "Epoch: 1/30... Training loss: 0.1683\n",
      "Epoch: 1/30... Training loss: 0.1663\n",
      "Epoch: 1/30... Training loss: 0.1689\n",
      "Epoch: 1/30... Training loss: 0.1685\n",
      "Epoch: 1/30... Training loss: 0.1753\n",
      "Epoch: 1/30... Training loss: 0.1725\n",
      "Epoch: 1/30... Training loss: 0.1651\n",
      "Epoch: 1/30... Training loss: 0.1802\n",
      "Epoch: 1/30... Training loss: 0.1782\n",
      "Epoch: 1/30... Training loss: 0.1743\n",
      "Epoch: 1/30... Training loss: 0.1788\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1661\n",
      "Epoch: 1/30... Training loss: 0.1695\n",
      "Epoch: 1/30... Training loss: 0.1665\n",
      "Epoch: 1/30... Training loss: 0.1692\n",
      "Epoch: 1/30... Training loss: 0.1675\n",
      "Epoch: 1/30... Training loss: 0.1952\n",
      "Epoch: 1/30... Training loss: 0.1599\n",
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1673\n",
      "Epoch: 1/30... Training loss: 0.1648\n",
      "Epoch: 1/30... Training loss: 0.1598\n",
      "Epoch: 1/30... Training loss: 0.1697\n",
      "Epoch: 1/30... Training loss: 0.1879\n",
      "Epoch: 1/30... Training loss: 0.1633\n",
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1818\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1912\n",
      "Epoch: 1/30... Training loss: 0.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1689\n",
      "Epoch: 1/30... Training loss: 0.1693\n",
      "Epoch: 1/30... Training loss: 0.1771\n",
      "Epoch: 1/30... Training loss: 0.1591\n",
      "Epoch: 1/30... Training loss: 0.1662\n",
      "Epoch: 1/30... Training loss: 0.1723\n",
      "Epoch: 1/30... Training loss: 0.1680\n",
      "Epoch: 1/30... Training loss: 0.1713\n",
      "Epoch: 1/30... Training loss: 0.1664\n",
      "Epoch: 1/30... Training loss: 0.1752\n",
      "Epoch: 1/30... Training loss: 0.1776\n",
      "Epoch: 1/30... Training loss: 0.1652\n",
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1642\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1626\n",
      "Epoch: 1/30... Training loss: 0.1723\n",
      "Epoch: 1/30... Training loss: 0.1714\n",
      "Epoch: 1/30... Training loss: 0.1677\n",
      "Epoch: 1/30... Training loss: 0.1634\n",
      "Epoch: 1/30... Training loss: 0.1669\n",
      "Epoch: 1/30... Training loss: 0.1576\n",
      "Epoch: 1/30... Training loss: 0.1732\n",
      "Epoch: 1/30... Training loss: 0.1728\n",
      "Epoch: 1/30... Training loss: 0.1609\n",
      "Epoch: 1/30... Training loss: 0.1673\n",
      "Epoch: 1/30... Training loss: 0.1667\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1578\n",
      "Epoch: 1/30... Training loss: 0.1631\n",
      "Epoch: 1/30... Training loss: 0.1709\n",
      "Epoch: 1/30... Training loss: 0.1599\n",
      "Epoch: 1/30... Training loss: 0.1832\n",
      "Epoch: 1/30... Training loss: 0.1536\n",
      "Epoch: 1/30... Training loss: 0.1689\n",
      "Epoch: 1/30... Training loss: 0.1765\n",
      "Epoch: 1/30... Training loss: 0.1647\n",
      "Epoch: 1/30... Training loss: 0.1775\n",
      "Epoch: 1/30... Training loss: 0.1717\n",
      "Epoch: 1/30... Training loss: 0.1690\n",
      "Epoch: 1/30... Training loss: 0.1634\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1568\n",
      "Epoch: 1/30... Training loss: 0.1759\n",
      "Epoch: 1/30... Training loss: 0.1805\n",
      "Epoch: 1/30... Training loss: 0.1690\n",
      "Epoch: 1/30... Training loss: 0.1574\n",
      "Epoch: 1/30... Training loss: 0.1778\n",
      "Epoch: 1/30... Training loss: 0.1741\n",
      "Epoch: 1/30... Training loss: 0.1799\n",
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1731\n",
      "Epoch: 1/30... Training loss: 0.1585\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1686\n",
      "Epoch: 1/30... Training loss: 0.1544\n",
      "Epoch: 1/30... Training loss: 0.1740\n",
      "Epoch: 1/30... Training loss: 0.1593\n",
      "Epoch: 1/30... Training loss: 0.1622\n",
      "Epoch: 1/30... Training loss: 0.1670\n",
      "Epoch: 1/30... Training loss: 0.1639\n",
      "Epoch: 1/30... Training loss: 0.1658\n",
      "Epoch: 1/30... Training loss: 0.1573\n",
      "Epoch: 1/30... Training loss: 0.1688\n",
      "Epoch: 1/30... Training loss: 0.1583\n",
      "Epoch: 1/30... Training loss: 0.1534\n",
      "Epoch: 1/30... Training loss: 0.1574\n",
      "Epoch: 1/30... Training loss: 0.1604\n",
      "Epoch: 1/30... Training loss: 0.1740\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1657\n",
      "Epoch: 1/30... Training loss: 0.1582\n",
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1613\n",
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1613\n",
      "Epoch: 1/30... Training loss: 0.1623\n",
      "Epoch: 1/30... Training loss: 0.1843\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1623\n",
      "Epoch: 1/30... Training loss: 0.1547\n",
      "Epoch: 1/30... Training loss: 0.1638\n",
      "Epoch: 1/30... Training loss: 0.1646\n",
      "Epoch: 1/30... Training loss: 0.1635\n",
      "Epoch: 1/30... Training loss: 0.1621\n",
      "Epoch: 1/30... Training loss: 0.1465\n",
      "Epoch: 1/30... Training loss: 0.1521\n",
      "Epoch: 1/30... Training loss: 0.1571\n",
      "Epoch: 1/30... Training loss: 0.1785\n",
      "Epoch: 1/30... Training loss: 0.1608\n",
      "Epoch: 1/30... Training loss: 0.1650\n",
      "Epoch: 1/30... Training loss: 0.1576\n",
      "Epoch: 1/30... Training loss: 0.1663\n",
      "Epoch: 1/30... Training loss: 0.1519\n",
      "Epoch: 1/30... Training loss: 0.1585\n",
      "Epoch: 1/30... Training loss: 0.1631\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1554\n",
      "Epoch: 1/30... Training loss: 0.1718\n",
      "Epoch: 1/30... Training loss: 0.1686\n",
      "Epoch: 1/30... Training loss: 0.1534\n",
      "Epoch: 1/30... Training loss: 0.1544\n",
      "Epoch: 1/30... Training loss: 0.1555\n",
      "Epoch: 1/30... Training loss: 0.1572\n",
      "Epoch: 1/30... Training loss: 0.1671\n",
      "Epoch: 1/30... Training loss: 0.1586\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1613\n",
      "Epoch: 1/30... Training loss: 0.1698\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1704\n",
      "Epoch: 1/30... Training loss: 0.1627\n",
      "Epoch: 1/30... Training loss: 0.1537\n",
      "Epoch: 1/30... Training loss: 0.1687\n",
      "Epoch: 1/30... Training loss: 0.1544\n",
      "Epoch: 1/30... Training loss: 0.1648\n",
      "Epoch: 1/30... Training loss: 0.1629\n",
      "Epoch: 1/30... Training loss: 0.1614\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1594\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1624\n",
      "Epoch: 1/30... Training loss: 0.1581\n",
      "Epoch: 1/30... Training loss: 0.1734\n",
      "Epoch: 1/30... Training loss: 0.1594\n",
      "Epoch: 1/30... Training loss: 0.1631\n",
      "Epoch: 1/30... Training loss: 0.1687\n",
      "Epoch: 1/30... Training loss: 0.1612\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1692\n",
      "Epoch: 1/30... Training loss: 0.1638\n",
      "Epoch: 1/30... Training loss: 0.1636\n",
      "Epoch: 1/30... Training loss: 0.1597\n",
      "Epoch: 1/30... Training loss: 0.1480\n",
      "Epoch: 1/30... Training loss: 0.1584\n",
      "Epoch: 1/30... Training loss: 0.1580\n",
      "Epoch: 1/30... Training loss: 0.1642\n",
      "Epoch: 1/30... Training loss: 0.1585\n",
      "Epoch: 1/30... Training loss: 0.1653\n",
      "Epoch: 1/30... Training loss: 0.1567\n",
      "Epoch: 1/30... Training loss: 0.1492\n",
      "Epoch: 1/30... Training loss: 0.1328\n",
      "Epoch: 1/30... Training loss: 0.1653\n",
      "Epoch: 1/30... Training loss: 0.1529\n",
      "Epoch: 1/30... Training loss: 0.1663\n",
      "Epoch: 1/30... Training loss: 0.1504\n",
      "Epoch: 1/30... Training loss: 0.1541\n",
      "Epoch: 1/30... Training loss: 0.1652\n",
      "Epoch: 1/30... Training loss: 0.1575\n",
      "Epoch: 1/30... Training loss: 0.1793\n",
      "Epoch: 1/30... Training loss: 0.1730\n",
      "Epoch: 1/30... Training loss: 0.1680\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1519\n",
      "Epoch: 1/30... Training loss: 0.1542\n",
      "Epoch: 1/30... Training loss: 0.1547\n",
      "Epoch: 1/30... Training loss: 0.1493\n",
      "Epoch: 1/30... Training loss: 0.1598\n",
      "Epoch: 1/30... Training loss: 0.1649\n",
      "Epoch: 1/30... Training loss: 0.1569\n",
      "Epoch: 1/30... Training loss: 0.1503\n",
      "Epoch: 1/30... Training loss: 0.1513\n",
      "Epoch: 1/30... Training loss: 0.1568\n",
      "Epoch: 1/30... Training loss: 0.1619\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1644\n",
      "Epoch: 1/30... Training loss: 0.1613\n",
      "Epoch: 1/30... Training loss: 0.1470\n",
      "Epoch: 1/30... Training loss: 0.1478\n",
      "Epoch: 1/30... Training loss: 0.1567\n",
      "Epoch: 1/30... Training loss: 0.1520\n",
      "Epoch: 1/30... Training loss: 0.1450\n",
      "Epoch: 1/30... Training loss: 0.1514\n",
      "Epoch: 1/30... Training loss: 0.1741\n",
      "Epoch: 1/30... Training loss: 0.1701\n",
      "Epoch: 1/30... Training loss: 0.1544\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1480\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1587\n",
      "Epoch: 1/30... Training loss: 0.1602\n",
      "Epoch: 1/30... Training loss: 0.1513\n",
      "Epoch: 1/30... Training loss: 0.1563\n",
      "Epoch: 1/30... Training loss: 0.1583\n",
      "Epoch: 1/30... Training loss: 0.1688\n",
      "Epoch: 1/30... Training loss: 0.1590\n",
      "Epoch: 1/30... Training loss: 0.1572\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1513\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1512\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1653\n",
      "Epoch: 1/30... Training loss: 0.1560\n",
      "Epoch: 1/30... Training loss: 0.1603\n",
      "Epoch: 1/30... Training loss: 0.1529\n",
      "Epoch: 1/30... Training loss: 0.1577\n",
      "Epoch: 1/30... Training loss: 0.1541\n",
      "Epoch: 1/30... Training loss: 0.1455\n",
      "Epoch: 1/30... Training loss: 0.1627\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1502\n",
      "Epoch: 1/30... Training loss: 0.1471\n",
      "Epoch: 1/30... Training loss: 0.1599\n",
      "Epoch: 1/30... Training loss: 0.1627\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1519\n",
      "Epoch: 1/30... Training loss: 0.1520\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1539\n",
      "Epoch: 1/30... Training loss: 0.1459\n",
      "Epoch: 1/30... Training loss: 0.1568\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1607\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1563\n",
      "Epoch: 1/30... Training loss: 0.1642\n",
      "Epoch: 1/30... Training loss: 0.1423\n",
      "Epoch: 1/30... Training loss: 0.1456\n",
      "Epoch: 1/30... Training loss: 0.1491\n",
      "Epoch: 1/30... Training loss: 0.1551\n",
      "Epoch: 1/30... Training loss: 0.1519\n",
      "Epoch: 1/30... Training loss: 0.1475\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1577\n",
      "Epoch: 1/30... Training loss: 0.1530\n",
      "Epoch: 1/30... Training loss: 0.1561\n",
      "Epoch: 1/30... Training loss: 0.1518\n",
      "Epoch: 1/30... Training loss: 0.1465\n",
      "Epoch: 1/30... Training loss: 0.1462\n",
      "Epoch: 1/30... Training loss: 0.1508\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1590\n",
      "Epoch: 1/30... Training loss: 0.1629\n",
      "Epoch: 1/30... Training loss: 0.1579\n",
      "Epoch: 1/30... Training loss: 0.1488\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1586\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1520\n",
      "Epoch: 1/30... Training loss: 0.1583\n",
      "Epoch: 1/30... Training loss: 0.1569\n",
      "Epoch: 1/30... Training loss: 0.1512\n",
      "Epoch: 1/30... Training loss: 0.1634\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1641\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1647\n",
      "Epoch: 1/30... Training loss: 0.1467\n",
      "Epoch: 1/30... Training loss: 0.1408\n",
      "Epoch: 1/30... Training loss: 0.1649\n",
      "Epoch: 1/30... Training loss: 0.1546\n",
      "Epoch: 1/30... Training loss: 0.1496\n",
      "Epoch: 1/30... Training loss: 0.1486\n",
      "Epoch: 1/30... Training loss: 0.1560\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1527\n",
      "Epoch: 1/30... Training loss: 0.1572\n",
      "Epoch: 1/30... Training loss: 0.1499\n",
      "Epoch: 1/30... Training loss: 0.1562\n",
      "Epoch: 1/30... Training loss: 0.1611\n",
      "Epoch: 1/30... Training loss: 0.1484\n",
      "Epoch: 1/30... Training loss: 0.1455\n",
      "Epoch: 1/30... Training loss: 0.1562\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1543\n",
      "Epoch: 1/30... Training loss: 0.1496\n",
      "Epoch: 1/30... Training loss: 0.1535\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1540\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1463\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1399\n",
      "Epoch: 1/30... Training loss: 0.1388\n",
      "Epoch: 1/30... Training loss: 0.1536\n",
      "Epoch: 1/30... Training loss: 0.1453\n",
      "Epoch: 1/30... Training loss: 0.1513\n",
      "Epoch: 1/30... Training loss: 0.1546\n",
      "Epoch: 1/30... Training loss: 0.1472\n",
      "Epoch: 1/30... Training loss: 0.1517\n",
      "Epoch: 1/30... Training loss: 0.1451\n",
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1541\n",
      "Epoch: 1/30... Training loss: 0.1575\n",
      "Epoch: 1/30... Training loss: 0.1529\n",
      "Epoch: 1/30... Training loss: 0.1469\n",
      "Epoch: 1/30... Training loss: 0.1482\n",
      "Epoch: 1/30... Training loss: 0.1541\n",
      "Epoch: 1/30... Training loss: 0.1452\n",
      "Epoch: 1/30... Training loss: 0.1547\n",
      "Epoch: 1/30... Training loss: 0.1475\n",
      "Epoch: 1/30... Training loss: 0.1452\n",
      "Epoch: 1/30... Training loss: 0.1491\n",
      "Epoch: 1/30... Training loss: 0.1491\n",
      "Epoch: 1/30... Training loss: 0.1559\n",
      "Epoch: 1/30... Training loss: 0.1476\n",
      "Epoch: 1/30... Training loss: 0.1408\n",
      "Epoch: 1/30... Training loss: 0.1495\n",
      "Epoch: 1/30... Training loss: 0.1483\n",
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1674\n",
      "Epoch: 1/30... Training loss: 0.1472\n",
      "Epoch: 1/30... Training loss: 0.1542\n",
      "Epoch: 1/30... Training loss: 0.1450\n",
      "Epoch: 1/30... Training loss: 0.1381\n",
      "Epoch: 1/30... Training loss: 0.1496\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1592\n",
      "Epoch: 1/30... Training loss: 0.1380\n",
      "Epoch: 1/30... Training loss: 0.1439\n",
      "Epoch: 1/30... Training loss: 0.1481\n",
      "Epoch: 1/30... Training loss: 0.1641\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1549\n",
      "Epoch: 1/30... Training loss: 0.1630\n",
      "Epoch: 1/30... Training loss: 0.1395\n",
      "Epoch: 1/30... Training loss: 0.1449\n",
      "Epoch: 1/30... Training loss: 0.1389\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1309\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1473\n",
      "Epoch: 1/30... Training loss: 0.1454\n",
      "Epoch: 1/30... Training loss: 0.1497\n",
      "Epoch: 1/30... Training loss: 0.1372\n",
      "Epoch: 1/30... Training loss: 0.1470\n",
      "Epoch: 1/30... Training loss: 0.1360\n",
      "Epoch: 1/30... Training loss: 0.1560\n",
      "Epoch: 1/30... Training loss: 0.1518\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1475\n",
      "Epoch: 1/30... Training loss: 0.1488\n",
      "Epoch: 1/30... Training loss: 0.1391\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1377\n",
      "Epoch: 1/30... Training loss: 0.1436\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1344\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1529\n",
      "Epoch: 1/30... Training loss: 0.1476\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1539\n",
      "Epoch: 1/30... Training loss: 0.1446\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1409\n",
      "Epoch: 1/30... Training loss: 0.1470\n",
      "Epoch: 1/30... Training loss: 0.1430\n",
      "Epoch: 1/30... Training loss: 0.1392\n",
      "Epoch: 1/30... Training loss: 0.1535\n",
      "Epoch: 1/30... Training loss: 0.1426\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1410\n",
      "Epoch: 1/30... Training loss: 0.1463\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1450\n",
      "Epoch: 1/30... Training loss: 0.1410\n",
      "Epoch: 1/30... Training loss: 0.1506\n",
      "Epoch: 1/30... Training loss: 0.1462\n",
      "Epoch: 1/30... Training loss: 0.1501\n",
      "Epoch: 1/30... Training loss: 0.1467\n",
      "Epoch: 1/30... Training loss: 0.1352\n",
      "Epoch: 1/30... Training loss: 0.1434\n",
      "Epoch: 1/30... Training loss: 0.1518\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1396\n",
      "Epoch: 1/30... Training loss: 0.1472\n",
      "Epoch: 1/30... Training loss: 0.1473\n",
      "Epoch: 1/30... Training loss: 0.1475\n",
      "Epoch: 1/30... Training loss: 0.1399\n",
      "Epoch: 1/30... Training loss: 0.1439\n",
      "Epoch: 1/30... Training loss: 0.1421\n",
      "Epoch: 1/30... Training loss: 0.1350\n",
      "Epoch: 1/30... Training loss: 0.1430\n",
      "Epoch: 1/30... Training loss: 0.1360\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1439\n",
      "Epoch: 1/30... Training loss: 0.1469\n",
      "Epoch: 1/30... Training loss: 0.1480\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1433\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1457\n",
      "Epoch: 1/30... Training loss: 0.1416\n",
      "Epoch: 1/30... Training loss: 0.1474\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1438\n",
      "Epoch: 1/30... Training loss: 0.1437\n",
      "Epoch: 1/30... Training loss: 0.1445\n",
      "Epoch: 1/30... Training loss: 0.1510\n",
      "Epoch: 1/30... Training loss: 0.1436\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1286\n",
      "Epoch: 1/30... Training loss: 0.1356\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1370\n",
      "Epoch: 1/30... Training loss: 0.1449\n",
      "Epoch: 1/30... Training loss: 0.1492\n",
      "Epoch: 1/30... Training loss: 0.1384\n",
      "Epoch: 1/30... Training loss: 0.1380\n",
      "Epoch: 1/30... Training loss: 0.1407\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1391\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1453\n",
      "Epoch: 1/30... Training loss: 0.1330\n",
      "Epoch: 1/30... Training loss: 0.1474\n",
      "Epoch: 1/30... Training loss: 0.1436\n",
      "Epoch: 1/30... Training loss: 0.1396\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1434\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1360\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1456\n",
      "Epoch: 1/30... Training loss: 0.1341\n",
      "Epoch: 1/30... Training loss: 0.1378\n",
      "Epoch: 1/30... Training loss: 0.1465\n",
      "Epoch: 1/30... Training loss: 0.1329\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1375\n",
      "Epoch: 1/30... Training loss: 0.1473\n",
      "Epoch: 1/30... Training loss: 0.1399\n",
      "Epoch: 1/30... Training loss: 0.1369\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1389\n",
      "Epoch: 1/30... Training loss: 0.1438\n",
      "Epoch: 1/30... Training loss: 0.1473\n",
      "Epoch: 1/30... Training loss: 0.1462\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1370\n",
      "Epoch: 1/30... Training loss: 0.1439\n",
      "Epoch: 1/30... Training loss: 0.1507\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1327\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1392\n",
      "Epoch: 1/30... Training loss: 0.1430\n",
      "Epoch: 1/30... Training loss: 0.1407\n",
      "Epoch: 1/30... Training loss: 0.1298\n",
      "Epoch: 1/30... Training loss: 0.1352\n",
      "Epoch: 1/30... Training loss: 0.1534\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1437\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1359\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1546\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1267\n",
      "Epoch: 1/30... Training loss: 0.1318\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1315\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1412\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1348\n",
      "Epoch: 1/30... Training loss: 0.1343\n",
      "Epoch: 1/30... Training loss: 0.1454\n",
      "Epoch: 1/30... Training loss: 0.1338\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1400\n",
      "Epoch: 1/30... Training loss: 0.1274\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1337\n",
      "Epoch: 1/30... Training loss: 0.1372\n",
      "Epoch: 1/30... Training loss: 0.1378\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1406\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1364\n",
      "Epoch: 1/30... Training loss: 0.1378\n",
      "Epoch: 1/30... Training loss: 0.1285\n",
      "Epoch: 1/30... Training loss: 0.1305\n",
      "Epoch: 1/30... Training loss: 0.1364\n",
      "Epoch: 1/30... Training loss: 0.1369\n",
      "Epoch: 1/30... Training loss: 0.1279\n",
      "Epoch: 1/30... Training loss: 0.1310\n",
      "Epoch: 1/30... Training loss: 0.1308\n",
      "Epoch: 1/30... Training loss: 0.1397\n",
      "Epoch: 1/30... Training loss: 0.1286\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1337\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1369\n",
      "Epoch: 1/30... Training loss: 0.1380\n",
      "Epoch: 1/30... Training loss: 0.1290\n",
      "Epoch: 1/30... Training loss: 0.1391\n",
      "Epoch: 1/30... Training loss: 0.1365\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1418\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1433\n",
      "Epoch: 1/30... Training loss: 0.1354\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1359\n",
      "Epoch: 1/30... Training loss: 0.1358\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1277\n",
      "Epoch: 1/30... Training loss: 0.1360\n",
      "Epoch: 1/30... Training loss: 0.1307\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1321\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1278\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1324\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1412\n",
      "Epoch: 1/30... Training loss: 0.1343\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1275\n",
      "Epoch: 1/30... Training loss: 0.1285\n",
      "Epoch: 1/30... Training loss: 0.1516\n",
      "Epoch: 1/30... Training loss: 0.1343\n",
      "Epoch: 1/30... Training loss: 0.1241\n",
      "Epoch: 1/30... Training loss: 0.1272\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1304\n",
      "Epoch: 1/30... Training loss: 0.1358\n",
      "Epoch: 1/30... Training loss: 0.1324\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1352\n",
      "Epoch: 1/30... Training loss: 0.1378\n",
      "Epoch: 1/30... Training loss: 0.1372\n",
      "Epoch: 1/30... Training loss: 0.1321\n",
      "Epoch: 1/30... Training loss: 0.1400\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1391\n",
      "Epoch: 1/30... Training loss: 0.1403\n",
      "Epoch: 1/30... Training loss: 0.1344\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1319\n",
      "Epoch: 1/30... Training loss: 0.1305\n",
      "Epoch: 1/30... Training loss: 0.1446\n",
      "Epoch: 1/30... Training loss: 0.1393\n",
      "Epoch: 1/30... Training loss: 0.1306\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1470\n",
      "Epoch: 1/30... Training loss: 0.1319\n",
      "Epoch: 1/30... Training loss: 0.1343\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1297\n",
      "Epoch: 1/30... Training loss: 0.1362\n",
      "Epoch: 1/30... Training loss: 0.1350\n",
      "Epoch: 1/30... Training loss: 0.1446\n",
      "Epoch: 1/30... Training loss: 0.1333\n",
      "Epoch: 1/30... Training loss: 0.1241\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1275\n",
      "Epoch: 1/30... Training loss: 0.1286\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1262\n",
      "Epoch: 1/30... Training loss: 0.1327\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1311\n",
      "Epoch: 1/30... Training loss: 0.1367\n",
      "Epoch: 1/30... Training loss: 0.1304\n",
      "Epoch: 1/30... Training loss: 0.1394\n",
      "Epoch: 1/30... Training loss: 0.1254\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1310\n",
      "Epoch: 1/30... Training loss: 0.1270\n",
      "Epoch: 1/30... Training loss: 0.1304\n",
      "Epoch: 1/30... Training loss: 0.1384\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1395\n",
      "Epoch: 1/30... Training loss: 0.1294\n",
      "Epoch: 1/30... Training loss: 0.1280\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1241\n",
      "Epoch: 1/30... Training loss: 0.1300\n",
      "Epoch: 1/30... Training loss: 0.1310\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1260\n",
      "Epoch: 1/30... Training loss: 0.1282\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1287\n",
      "Epoch: 1/30... Training loss: 0.1226\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1325\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1329\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1360\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1298\n",
      "Epoch: 1/30... Training loss: 0.1261\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1337\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1324\n",
      "Epoch: 1/30... Training loss: 0.1358\n",
      "Epoch: 1/30... Training loss: 0.1280\n",
      "Epoch: 1/30... Training loss: 0.1283\n",
      "Epoch: 1/30... Training loss: 0.1344\n",
      "Epoch: 1/30... Training loss: 0.1300\n",
      "Epoch: 1/30... Training loss: 0.1275\n",
      "Epoch: 1/30... Training loss: 0.1376\n",
      "Epoch: 1/30... Training loss: 0.1245\n",
      "Epoch: 1/30... Training loss: 0.1276\n",
      "Epoch: 1/30... Training loss: 0.1322\n",
      "Epoch: 1/30... Training loss: 0.1273\n",
      "Epoch: 1/30... Training loss: 0.1336\n",
      "Epoch: 1/30... Training loss: 0.1322\n",
      "Epoch: 1/30... Training loss: 0.1287\n",
      "Epoch: 1/30... Training loss: 0.1290\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1253\n",
      "Epoch: 1/30... Training loss: 0.1265\n",
      "Epoch: 1/30... Training loss: 0.1325\n",
      "Epoch: 1/30... Training loss: 0.1304\n",
      "Epoch: 1/30... Training loss: 0.1362\n",
      "Epoch: 1/30... Training loss: 0.1292\n",
      "Epoch: 1/30... Training loss: 0.1368\n",
      "Epoch: 1/30... Training loss: 0.1307\n",
      "Epoch: 1/30... Training loss: 0.1355\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1246\n",
      "Epoch: 1/30... Training loss: 0.1413\n",
      "Epoch: 1/30... Training loss: 0.1262\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1308\n",
      "Epoch: 1/30... Training loss: 0.1293\n",
      "Epoch: 1/30... Training loss: 0.1199\n",
      "Epoch: 1/30... Training loss: 0.1323\n",
      "Epoch: 1/30... Training loss: 0.1293\n",
      "Epoch: 1/30... Training loss: 0.1327\n",
      "Epoch: 1/30... Training loss: 0.1203\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1269\n",
      "Epoch: 1/30... Training loss: 0.1218\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1355\n",
      "Epoch: 1/30... Training loss: 0.1264\n",
      "Epoch: 1/30... Training loss: 0.1363\n",
      "Epoch: 1/30... Training loss: 0.1333\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1287\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1329\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1318\n",
      "Epoch: 1/30... Training loss: 0.1261\n",
      "Epoch: 1/30... Training loss: 0.1213\n",
      "Epoch: 1/30... Training loss: 0.1291\n",
      "Epoch: 1/30... Training loss: 0.1240\n",
      "Epoch: 1/30... Training loss: 0.1204\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1350\n",
      "Epoch: 1/30... Training loss: 0.1262\n",
      "Epoch: 1/30... Training loss: 0.1272\n",
      "Epoch: 1/30... Training loss: 0.1276\n",
      "Epoch: 1/30... Training loss: 0.1417\n",
      "Epoch: 1/30... Training loss: 0.1305\n",
      "Epoch: 1/30... Training loss: 0.1214\n",
      "Epoch: 1/30... Training loss: 0.1417\n",
      "Epoch: 1/30... Training loss: 0.1232\n",
      "Epoch: 1/30... Training loss: 0.1192\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1412\n",
      "Epoch: 1/30... Training loss: 0.1250\n",
      "Epoch: 1/30... Training loss: 0.1258\n",
      "Epoch: 1/30... Training loss: 0.1247\n",
      "Epoch: 1/30... Training loss: 0.1212\n",
      "Epoch: 1/30... Training loss: 0.1379\n",
      "Epoch: 1/30... Training loss: 0.1351\n",
      "Epoch: 1/30... Training loss: 0.1250\n",
      "Epoch: 1/30... Training loss: 0.1194\n",
      "Epoch: 1/30... Training loss: 0.1262\n",
      "Epoch: 1/30... Training loss: 0.1286\n",
      "Epoch: 1/30... Training loss: 0.1293\n",
      "Epoch: 1/30... Training loss: 0.1422\n",
      "Epoch: 1/30... Training loss: 0.1256\n",
      "Epoch: 1/30... Training loss: 0.1247\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1335\n",
      "Epoch: 1/30... Training loss: 0.1267\n",
      "Epoch: 1/30... Training loss: 0.1390\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1183\n",
      "Epoch: 1/30... Training loss: 0.1279\n",
      "Epoch: 1/30... Training loss: 0.1290\n",
      "Epoch: 1/30... Training loss: 0.1270\n",
      "Epoch: 1/30... Training loss: 0.1269\n",
      "Epoch: 1/30... Training loss: 0.1255\n",
      "Epoch: 1/30... Training loss: 0.1397\n",
      "Epoch: 1/30... Training loss: 0.1267\n",
      "Epoch: 1/30... Training loss: 0.1285\n",
      "Epoch: 1/30... Training loss: 0.1297\n",
      "Epoch: 1/30... Training loss: 0.1243\n",
      "Epoch: 1/30... Training loss: 0.1277\n",
      "Epoch: 1/30... Training loss: 0.1308\n",
      "Epoch: 1/30... Training loss: 0.1287\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1282\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1256\n",
      "Epoch: 2/30... Training loss: 0.1327\n",
      "Epoch: 2/30... Training loss: 0.1276\n",
      "Epoch: 2/30... Training loss: 0.1285\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1214\n",
      "Epoch: 2/30... Training loss: 0.1278\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1201\n",
      "Epoch: 2/30... Training loss: 0.1299\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1237\n",
      "Epoch: 2/30... Training loss: 0.1266\n",
      "Epoch: 2/30... Training loss: 0.1157\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1286\n",
      "Epoch: 2/30... Training loss: 0.1216\n",
      "Epoch: 2/30... Training loss: 0.1311\n",
      "Epoch: 2/30... Training loss: 0.1276\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1261\n",
      "Epoch: 2/30... Training loss: 0.1233\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1251\n",
      "Epoch: 2/30... Training loss: 0.1256\n",
      "Epoch: 2/30... Training loss: 0.1301\n",
      "Epoch: 2/30... Training loss: 0.1242\n",
      "Epoch: 2/30... Training loss: 0.1273\n",
      "Epoch: 2/30... Training loss: 0.1332\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1211\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1204\n",
      "Epoch: 2/30... Training loss: 0.1312\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1299\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1272\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1262\n",
      "Epoch: 2/30... Training loss: 0.1201\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1253\n",
      "Epoch: 2/30... Training loss: 0.1287\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1291\n",
      "Epoch: 2/30... Training loss: 0.1328\n",
      "Epoch: 2/30... Training loss: 0.1330\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1282\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1193\n",
      "Epoch: 2/30... Training loss: 0.1333\n",
      "Epoch: 2/30... Training loss: 0.1262\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1286\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1305\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1326\n",
      "Epoch: 2/30... Training loss: 0.1252\n",
      "Epoch: 2/30... Training loss: 0.1274\n",
      "Epoch: 2/30... Training loss: 0.1265\n",
      "Epoch: 2/30... Training loss: 0.1147\n",
      "Epoch: 2/30... Training loss: 0.1362\n",
      "Epoch: 2/30... Training loss: 0.1193\n",
      "Epoch: 2/30... Training loss: 0.1255\n",
      "Epoch: 2/30... Training loss: 0.1280\n",
      "Epoch: 2/30... Training loss: 0.1197\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1214\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1275\n",
      "Epoch: 2/30... Training loss: 0.1339\n",
      "Epoch: 2/30... Training loss: 0.1261\n",
      "Epoch: 2/30... Training loss: 0.1267\n",
      "Epoch: 2/30... Training loss: 0.1267\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1311\n",
      "Epoch: 2/30... Training loss: 0.1260\n",
      "Epoch: 2/30... Training loss: 0.1246\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1329\n",
      "Epoch: 2/30... Training loss: 0.1286\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1225\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1234\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1277\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1308\n",
      "Epoch: 2/30... Training loss: 0.1244\n",
      "Epoch: 2/30... Training loss: 0.1271\n",
      "Epoch: 2/30... Training loss: 0.1310\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1341\n",
      "Epoch: 2/30... Training loss: 0.1236\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1287\n",
      "Epoch: 2/30... Training loss: 0.1287\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1298\n",
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1220\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1300\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1158\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1207\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1254\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1216\n",
      "Epoch: 2/30... Training loss: 0.1193\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1218\n",
      "Epoch: 2/30... Training loss: 0.1313\n",
      "Epoch: 2/30... Training loss: 0.1278\n",
      "Epoch: 2/30... Training loss: 0.1156\n",
      "Epoch: 2/30... Training loss: 0.1208\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1281\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1252\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1261\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1207\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1175\n",
      "Epoch: 2/30... Training loss: 0.1289\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1166\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1184\n",
      "Epoch: 2/30... Training loss: 0.1254\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1228\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1243\n",
      "Epoch: 2/30... Training loss: 0.1211\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1175\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1164\n",
      "Epoch: 2/30... Training loss: 0.1229\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1296\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1233\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1257\n",
      "Epoch: 2/30... Training loss: 0.1273\n",
      "Epoch: 2/30... Training loss: 0.1295\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1324\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1249\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1174\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1157\n",
      "Epoch: 2/30... Training loss: 0.1275\n",
      "Epoch: 2/30... Training loss: 0.1264\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1260\n",
      "Epoch: 2/30... Training loss: 0.1262\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1207\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1180\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1298\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1216\n",
      "Epoch: 2/30... Training loss: 0.1215\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1222\n",
      "Epoch: 2/30... Training loss: 0.1204\n",
      "Epoch: 2/30... Training loss: 0.1225\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1156\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1189\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1229\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1253\n",
      "Epoch: 2/30... Training loss: 0.1206\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1109\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1290\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1264\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1171\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1328\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1164\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1177\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1340\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1204\n",
      "Epoch: 2/30... Training loss: 0.1164\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1218\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1189\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1157\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1177\n",
      "Epoch: 2/30... Training loss: 0.1168\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1166\n",
      "Epoch: 2/30... Training loss: 0.1222\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1158\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1214\n",
      "Epoch: 2/30... Training loss: 0.1097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1237\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1238\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1175\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1233\n",
      "Epoch: 2/30... Training loss: 0.1150\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1166\n",
      "Epoch: 2/30... Training loss: 0.1204\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1147\n",
      "Epoch: 2/30... Training loss: 0.1206\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1200\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1242\n",
      "Epoch: 2/30... Training loss: 0.1218\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1177\n",
      "Epoch: 2/30... Training loss: 0.1214\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1072\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1174\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1268\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1231\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1157\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1190\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1200\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1085\n",
      "Epoch: 2/30... Training loss: 0.1168\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1147\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.1221\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1150\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1037\n",
      "Epoch: 2/30... Training loss: 0.1066\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1066\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1037\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1085\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1156\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1180\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.1066\n",
      "Epoch: 2/30... Training loss: 0.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0953\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1109\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1009\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1046\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1002\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1157\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1119\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1119\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1046\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1085\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1181\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.0969\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1072\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.1009\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.0951\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1002\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1046\n",
      "Epoch: 2/30... Training loss: 0.0993\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0936\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.0944\n",
      "Epoch: 2/30... Training loss: 0.1047\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.1097\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.0997\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.0958\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.0956\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.0953\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1047\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.0956\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0945\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.0919\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.0997\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.0992\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.0907\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.0993\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.0996\n",
      "Epoch: 2/30... Training loss: 0.0953\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.1050\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.0960\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.0957\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.0923\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1060\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.0951\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1046\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.0925\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.0925\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0930\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1119\n",
      "Epoch: 2/30... Training loss: 0.0963\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.0974\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.1009\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1005\n",
      "Epoch: 2/30... Training loss: 0.0954\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.0935\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.0904\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.0965\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0958\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.0993\n",
      "Epoch: 2/30... Training loss: 0.0964\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.0950\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0993\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.0960\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0996\n",
      "Epoch: 2/30... Training loss: 0.0969\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.0943\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.0945\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.0941\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.0944\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.0920\n",
      "Epoch: 2/30... Training loss: 0.0946\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.0942\n",
      "Epoch: 2/30... Training loss: 0.0946\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.0906\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0919\n",
      "Epoch: 2/30... Training loss: 0.0883\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.0910\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.0930\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.0941\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.1072\n",
      "Epoch: 2/30... Training loss: 0.0933\n",
      "Epoch: 2/30... Training loss: 0.0973\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.0937\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.1009\n",
      "Epoch: 2/30... Training loss: 0.0918\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.0974\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.0963\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.0997\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0912\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.0970\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.0929\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0932\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.0951\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.0964\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.0933\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.0970\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0945\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.0953\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.0992\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0920\n",
      "Epoch: 2/30... Training loss: 0.0941\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.1005\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0968\n",
      "Epoch: 3/30... Training loss: 0.1012\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.1009\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0966\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.1014\n",
      "Epoch: 3/30... Training loss: 0.1013\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.1005\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.1007\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.1048\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.1038\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.0987\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.1106\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.1067\n",
      "Epoch: 3/30... Training loss: 0.1032\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0994\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.1010\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.1004\n",
      "Epoch: 3/30... Training loss: 0.1061\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.1020\n",
      "Epoch: 3/30... Training loss: 0.0981\n",
      "Epoch: 3/30... Training loss: 0.1028\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.1018\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.1016\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0999\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.1016\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.1025\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0981\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.1001\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.1010\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0968\n",
      "Epoch: 3/30... Training loss: 0.1019\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.1019\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.1043\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.1001\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.1000\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.1001\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0994\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0984\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.1061\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.1018\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.1005\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.1036\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.1030\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.1030\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0981\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0984\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0995\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0973\n",
      "Epoch: 3/30... Training loss: 0.1040\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.1009\n",
      "Epoch: 3/30... Training loss: 0.0999\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.1012\n",
      "Epoch: 3/30... Training loss: 0.0973\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.1016\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0992\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.1022\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0992\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0992\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.1000\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.1006\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0836\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0999\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0987\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.1009\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0813\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0962\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0831\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0779\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0777\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0995\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.1011\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0836\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0835\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0808\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0808\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0827\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0828\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0807\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0815\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0807\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0774\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0814\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0836\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0830\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0820\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0789\n",
      "Epoch: 3/30... Training loss: 0.0827\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0830\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0830\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0835\n",
      "Epoch: 3/30... Training loss: 0.0835\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0806\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0788\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0822\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0825\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0769\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0816\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0835\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0761\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0831\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0962\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0818\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0824\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0804\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0763\n",
      "Epoch: 3/30... Training loss: 0.0820\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0809\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0792\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0817\n",
      "Epoch: 3/30... Training loss: 0.0835\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0826\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0831\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0816\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0815\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0818\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0809\n",
      "Epoch: 3/30... Training loss: 0.0896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0831\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0802\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0806\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0818\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0836\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0808\n",
      "Epoch: 3/30... Training loss: 0.0793\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0792\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0816\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0926\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0908\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0888\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0944\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0916\n",
      "Epoch: 4/30... Training loss: 0.0954\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0907\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0909\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0922\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0913\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0899\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0926\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0925\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0960\n",
      "Epoch: 4/30... Training loss: 0.0897\n",
      "Epoch: 4/30... Training loss: 0.0905\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0900\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0902\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0909\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0897\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0903\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0918\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0923\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0897\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0909\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0868\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0903\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0890\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0905\n",
      "Epoch: 4/30... Training loss: 0.0881\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0902\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0901\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0884\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0935\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0882\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0905\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0868\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0920\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0752\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0766\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0747\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0746\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0888\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0910\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0737\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0890\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0754\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0754\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0890\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0888\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0929\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0757\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0741\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0881\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0756\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0766\n",
      "Epoch: 4/30... Training loss: 0.0799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0737\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0750\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0762\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0924\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0882\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0767\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0748\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0754\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0741\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0916\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0738\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0735\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0764\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0761\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0751\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0739\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0732\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0714\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0740\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0761\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0732\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0767\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0751\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0723\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0722\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0759\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0758\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0722\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0902\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0751\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0743\n",
      "Epoch: 4/30... Training loss: 0.0752\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0758\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0753\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0767\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0738\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0705\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0862\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0843\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0843\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0855\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0854\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0875\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0882\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0721\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0865\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0869\n",
      "Epoch: 5/30... Training loss: 0.0843\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0713\n",
      "Epoch: 5/30... Training loss: 0.0889\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0875\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0728\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0863\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0891\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0887\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0857\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0848\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0862\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0865\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0707\n",
      "Epoch: 5/30... Training loss: 0.0849\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0710\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0855\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0865\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0721\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0857\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0869\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0734\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0876\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0720\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0860\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0727\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0707\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0718\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0853\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0861\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0715\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0860\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0724\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0849\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0724\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0708\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0714\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0853\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0699\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0883\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0854\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0727\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0718\n",
      "Epoch: 5/30... Training loss: 0.0703\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0705\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0865\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0857\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0728\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0864\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0724\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0715\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0719\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0849\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0818\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0823\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0693\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0835\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0830\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0833\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0847\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0722\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0711\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0662\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0837\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0844\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0840\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0855\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0831\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0690\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0838\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0686\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0839\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0711\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0827\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0689\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0827\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0834\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0827\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0832\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0838\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0829\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0699\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0817\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0838\n",
      "Epoch: 6/30... Training loss: 0.0774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0852\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0833\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0709\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0709\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0697\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0703\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0684\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0704\n",
      "Epoch: 6/30... Training loss: 0.0706\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0818\n",
      "Epoch: 6/30... Training loss: 0.0699\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0698\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0839\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0706\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0705\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0711\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0838\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0833\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0697\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0693\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0694\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0648\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0827\n",
      "Epoch: 7/30... Training loss: 0.0679\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0813\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0812\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0673\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0696\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0824\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0819\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0693\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0854\n",
      "Epoch: 7/30... Training loss: 0.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0683\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0702\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0848\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0812\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0827\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0826\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0691\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0681\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0812\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0817\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0818\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0823\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0699\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0675\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0826\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0698\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0698\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0813\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0701\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0662\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0693\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0697\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0689\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0701\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0835\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0837\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0696\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0696\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0692\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0813\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0687\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0694\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0695\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0818\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0699\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0816\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0707\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0818\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0815\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0681\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0812\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0815\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0688\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0702\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0823\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0832\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0685\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0832\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0677\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0815\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0689\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0684\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0801\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0803\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0829\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0810\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0812\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0681\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0849\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0801\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0668\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0691\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0846\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0814\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0801\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0830\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0688\n",
      "Epoch: 8/30... Training loss: 0.0686\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0812\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0692\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0818\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0692\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0670\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0660\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0692\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0823\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0811\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0691\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0687\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0812\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0821\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0691\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0683\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0681\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0679\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0809\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0800\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0819\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0815\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0688\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0809\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0686\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0690\n",
      "Epoch: 8/30... Training loss: 0.0819\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0800\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0696\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0803\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0685\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0684\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0692\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0801\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0670\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0687\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0822\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0681\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0687\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0811\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0682\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0800\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0809\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0812\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0680\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0690\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0810\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0838\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0821\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0682\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0803\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0671\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0668\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0798\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0810\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0817\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0795\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0810\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0811\n",
      "Epoch: 9/30... Training loss: 0.0795\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0678\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0669\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0675\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0683\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0806\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0829\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0663\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0800\n",
      "Epoch: 9/30... Training loss: 0.0683\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0685\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0673\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0816\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0672\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0673\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0674\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0794\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0800\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0675\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0813\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0678\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0812\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0808\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0817\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0672\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0685\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0807\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0680\n",
      "Epoch: 9/30... Training loss: 0.0665\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0794\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0794\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0815\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0795\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0827\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0685\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0685\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0798\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0657\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0678\n",
      "Epoch: 9/30... Training loss: 0.0841\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0673\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0684\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0794\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0677\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0684\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0683\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0807\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0796\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0796\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0677\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0673\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0661\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0678\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0792\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0823\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0688\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0678\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0796\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0692\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0689\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0821\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0792\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0688\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0684\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0680\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0688\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0820\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0802\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0682\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0672\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0812\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0672\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0799\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0666\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0661\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0796\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0810\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0692\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0814\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0671\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0802\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0684\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0666\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0692\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0797\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0669\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0808\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0657\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0806\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0797\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0659\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0677\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0692\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0689\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0671\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0689\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0671\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0681\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0799\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0811\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0800\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0800\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0802\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0685\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0683\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0797\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0786\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0796\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0670\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0679\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0821\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0685\n",
      "Epoch: 11/30... Training loss: 0.0633\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0786\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0812\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0786\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0666\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0673\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0793\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0806\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0806\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0796\n",
      "Epoch: 11/30... Training loss: 0.0674\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0665\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0682\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0817\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0804\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0793\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0679\n",
      "Epoch: 11/30... Training loss: 0.0813\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0787\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0687\n",
      "Epoch: 11/30... Training loss: 0.0799\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0665\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0666\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0830\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0662\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0667\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0673\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0813\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0807\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0655\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0804\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0787\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0685\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0676\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0795\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0658\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0787\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0675\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0800\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0807\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0651\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0787\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0797\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0818\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0806\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0687\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0786\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0683\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0676\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0683\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0687\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0793\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0673\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0665\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0799\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0672\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0784\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0669\n",
      "Epoch: 12/30... Training loss: 0.0671\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0784\n",
      "Epoch: 12/30... Training loss: 0.0809\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0799\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0659\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0685\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0651\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0805\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0803\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0787\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0795\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0787\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0801\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0797\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0805\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0669\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0626\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0655\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0797\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0835\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0800\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0668\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0683\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0677\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0797\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0796\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0679\n",
      "Epoch: 12/30... Training loss: 0.0676\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0673\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0808\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0672\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0674\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0811\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0795\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0784\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0676\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0809\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0797\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0661\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0808\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0683\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0803\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0801\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0804\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0792\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0801\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0803\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0806\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0671\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0685\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0665\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0655\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0787\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0643\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0677\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0661\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0809\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0673\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0802\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0812\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0793\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0808\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0675\n",
      "Epoch: 13/30... Training loss: 0.0803\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0656\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0794\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0807\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0683\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0797\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0642\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0672\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0681\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0681\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0800\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0791\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0799\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0690\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0670\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0774\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0792\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0821\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0797\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0684\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0797\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0671\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0812\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0683\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0676\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0668\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0680\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0679\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0687\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0690\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0791\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0690\n",
      "Epoch: 13/30... Training loss: 0.0680\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0656\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0672\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0793\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0664\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0663\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0790\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0670\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0774\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0793\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0690\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0808\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0674\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0808\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0665\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0673\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0672\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0673\n",
      "Epoch: 13/30... Training loss: 0.0676\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0803\n",
      "Epoch: 13/30... Training loss: 0.0682\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0672\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0809\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0679\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0681\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0797\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0677\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0671\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0685\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0649\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0817\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0805\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0799\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0807\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0661\n",
      "Epoch: 14/30... Training loss: 0.0682\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0670\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0770\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0673\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0795\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0800\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0796\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0800\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0811\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0682\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0786\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0673\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0681\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0782\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0785\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0793\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0681\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0786\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0685\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0672\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0676\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0806\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0770\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0785\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0770\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0672\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0794\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0786\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0800\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0662\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0680\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0667\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0677\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0674\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0671\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0770\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0770\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0800\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0655\n",
      "Epoch: 14/30... Training loss: 0.0785\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0670\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0669\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0680\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0795\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0819\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0658\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0799\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0661\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0664\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0797\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0788\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0819\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0657\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0675\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0793\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0814\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0673\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0808\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0678\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0790\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0814\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0800\n",
      "Epoch: 15/30... Training loss: 0.0668\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0662\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0682\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0655\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0796\n",
      "Epoch: 15/30... Training loss: 0.0670\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0671\n",
      "Epoch: 15/30... Training loss: 0.0805\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0675\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0821\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0789\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0631\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0799\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0667\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0675\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0671\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0814\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0665\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0669\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0800\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0663\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0673\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0804\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0676\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0815\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0796\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0668\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0813\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0788\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0787\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0663\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0808\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0789\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0793\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0808\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0799\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0664\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0797\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0674\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0788\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0680\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0663\n",
      "Epoch: 15/30... Training loss: 0.0674\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0821\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0665\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0655\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0838\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0793\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0790\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0670\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0811\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0795\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0787\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0671\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0801\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0798\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0668\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0672\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0670\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0684\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0794\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0671\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0675\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0659\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0684\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0796\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0789\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0669\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0650\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0786\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0675\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0667\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0794\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0787\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0666\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0802\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0789\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0667\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0805\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0795\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0786\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0792\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0821\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0669\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0653\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0672\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0825\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0793\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0672\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0794\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0790\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0669\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0786\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0790\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0684\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0651\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0658\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0800\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0670\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0788\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0642\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0802\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0669\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0661\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0676\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0672\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0797\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0808\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0656\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0657\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0777\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0800\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0790\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0789\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0789\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0662\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0784\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0676\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0666\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0803\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0813\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0661\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0784\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0805\n",
      "Epoch: 17/30... Training loss: 0.0794\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0811\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0788\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0782\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0674\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0788\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0789\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0672\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0807\n",
      "Epoch: 17/30... Training loss: 0.0777\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0782\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0791\n",
      "Epoch: 17/30... Training loss: 0.0665\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0784\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0784\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0676\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0674\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0681\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0804\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0668\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0785\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0777\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0792\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0673\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0832\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0782\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0675\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0669\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0681\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0795\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0636\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0804\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0788\n",
      "Epoch: 17/30... Training loss: 0.0792\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0799\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0675\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0668\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0658\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0677\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0658\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0670\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0810\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0789\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0789\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0671\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0660\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0783\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0645\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0810\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0645\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0792\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0669\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0800\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0803\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0799\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0782\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0786\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0823\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0782\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0796\n",
      "Epoch: 18/30... Training loss: 0.0788\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0804\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0784\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0661\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0796\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0675\n",
      "Epoch: 18/30... Training loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0664\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0795\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0654\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0813\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0658\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0788\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0796\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0668\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0782\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0811\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0677\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0805\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0795\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0801\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0685\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0668\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0674\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0685\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0664\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0668\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0660\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0806\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0665\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0791\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0668\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0670\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0799\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0679\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0677\n",
      "Epoch: 19/30... Training loss: 0.0668\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0782\n",
      "Epoch: 19/30... Training loss: 0.0634\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0798\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0665\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0791\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0660\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0785\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0670\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0671\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0795\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0631\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0778\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0793\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0793\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0810\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0789\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0795\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0663\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0674\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0679\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0790\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0670\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0780\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0679\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0797\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0782\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0801\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0672\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0665\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0653\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0681\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0665\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0816\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0652\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0681\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0792\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0792\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0790\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0785\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0665\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0673\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0791\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0829\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0676\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0679\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0666\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0805\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0674\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0680\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0673\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0795\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0801\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0794\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0663\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0791\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0818\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0786\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0658\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0680\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0644\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0668\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0782\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0676\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0798\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0642\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0798\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0800\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0678\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0791\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0666\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0786\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0659\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0794\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0820\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0653\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0803\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0674\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0793\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0653\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0782\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0803\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0671\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0791\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0785\n",
      "Epoch: 20/30... Training loss: 0.0656\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0792\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0784\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0782\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0803\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0802\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0668\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0672\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0795\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0785\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0784\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0656\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0676\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0800\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0680\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0806\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0678\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0795\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0660\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0661\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0788\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0671\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0669\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0782\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0664\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0781\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0646\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0685\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0663\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0679\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0800\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0791\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0676\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0776\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0679\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0675\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0670\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0669\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0674\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0789\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0636\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0776\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0667\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0656\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0797\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0673\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0660\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0676\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0649\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0789\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0677\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0785\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0670\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0672\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0799\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0807\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0675\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0783\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0785\n",
      "Epoch: 21/30... Training loss: 0.0657\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0672\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0825\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0681\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0674\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0663\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0668\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0805\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0676\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0806\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0792\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0791\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0803\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0787\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0653\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0793\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0800\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0683\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0791\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0683\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0804\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0667\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0677\n",
      "Epoch: 21/30... Training loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0661\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0798\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0653\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0666\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0665\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0790\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0786\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0664\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0662\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0792\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0794\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0797\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0668\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0780\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0680\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0679\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0787\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0664\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0677\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0653\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0786\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0669\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0671\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0780\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0683\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0782\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0683\n",
      "Epoch: 22/30... Training loss: 0.0759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0671\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0670\n",
      "Epoch: 22/30... Training loss: 0.0785\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0680\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0663\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0798\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0787\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0654\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0791\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0648\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0643\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0815\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0672\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0799\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0665\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0671\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0807\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0671\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0674\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0782\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0670\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0677\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0680\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0674\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0791\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0787\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0799\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0672\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0674\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0666\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0683\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0798\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0674\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0798\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0793\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0666\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0658\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0784\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0676\n",
      "Epoch: 23/30... Training loss: 0.0600\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0797\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0672\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0660\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0662\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0788\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0799\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0790\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0679\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0780\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0679\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0791\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0785\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0675\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0791\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0669\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0784\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0780\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0662\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0790\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0662\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0789\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0672\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0664\n",
      "Epoch: 23/30... Training loss: 0.0802\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0656\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0657\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0785\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0672\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0671\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0808\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0669\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0795\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0672\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0671\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0671\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0789\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0638\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0659\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0790\n",
      "Epoch: 23/30... Training loss: 0.0784\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0814\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0676\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0787\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0666\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0663\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0790\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0674\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0788\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0795\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0789\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0658\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0672\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0799\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0654\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0673\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0799\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0795\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0794\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0783\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0799\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0789\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0664\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0787\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0790\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0678\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0664\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0788\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0679\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0666\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0789\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0792\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0787\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0786\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0681\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0671\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0666\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0790\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0654\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0661\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0663\n",
      "Epoch: 24/30... Training loss: 0.0681\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0651\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0798\n",
      "Epoch: 24/30... Training loss: 0.0659\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0679\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0651\n",
      "Epoch: 24/30... Training loss: 0.0659\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0787\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0783\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0667\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0797\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0660\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0673\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0678\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0795\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0797\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0785\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0799\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0676\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0788\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0798\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0677\n",
      "Epoch: 24/30... Training loss: 0.0639\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0784\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0660\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0659\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0676\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0653\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0791\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0674\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0798\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0783\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0794\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0782\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0783\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0652\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0784\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0659\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0661\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0664\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0670\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0674\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0802\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0810\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0770\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0783\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0676\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0667\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0798\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0666\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0770\n",
      "Epoch: 25/30... Training loss: 0.0803\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0783\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0781\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0794\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0788\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0789\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0802\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0813\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0772\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0667\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0676\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0772\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0772\n",
      "Epoch: 25/30... Training loss: 0.0658\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0645\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0782\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0670\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0785\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0658\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0823\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0780\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0801\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0796\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0785\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0672\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0804\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0801\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0672\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0659\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0791\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0782\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0666\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0660\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0655\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0652\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0659\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0688\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0681\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0793\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0817\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0666\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0659\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0790\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0672\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0801\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0664\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0656\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0778\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0783\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0668\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0778\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0680\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0688\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0655\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0648\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0804\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0664\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0792\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0788\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0788\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0795\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0780\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0799\n",
      "Epoch: 26/30... Training loss: 0.0646\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0785\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0779\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0795\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0796\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0789\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0662\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0636\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0778\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0798\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0792\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0681\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0780\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0789\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0785\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0780\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0776\n",
      "Epoch: 26/30... Training loss: 0.0795\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0787\n",
      "Epoch: 26/30... Training loss: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0669\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0797\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0688\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0665\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0665\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0805\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0681\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0800\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0787\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0672\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0786\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0659\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0675\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0671\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0783\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0800\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0675\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0799\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0657\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0779\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0796\n",
      "Epoch: 27/30... Training loss: 0.0649\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0652\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0788\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0642\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0669\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0657\n",
      "Epoch: 27/30... Training loss: 0.0652\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0827\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0789\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0819\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0657\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0664\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0809\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0690\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0787\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0811\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0674\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0791\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0659\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0787\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0671\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0690\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0804\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0800\n",
      "Epoch: 27/30... Training loss: 0.0667\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0668\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0792\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0628\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0796\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0786\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0783\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0673\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0796\n",
      "Epoch: 27/30... Training loss: 0.0797\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0804\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0667\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0782\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0674\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0787\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0788\n",
      "Epoch: 27/30... Training loss: 0.0674\n",
      "Epoch: 27/30... Training loss: 0.0805\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0667\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0804\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0805\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0665\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0649\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0781\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0782\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0675\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0783\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0781\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0673\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0795\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0666\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0799\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0776\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0676\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0794\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0781\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0662\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0667\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0678\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0788\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0668\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0790\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0670\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0794\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0663\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0667\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0671\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0801\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0659\n",
      "Epoch: 28/30... Training loss: 0.0777\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0777\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0783\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0797\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0673\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0803\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0671\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0678\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0796\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0798\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0668\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0669\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0781\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0812\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0788\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0805\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0642\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0656\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0674\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0786\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0774\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0811\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0661\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0671\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0800\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0681\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0657\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0678\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0676\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0793\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0645\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0806\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0791\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0774\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0801\n",
      "Epoch: 28/30... Training loss: 0.0795\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0681\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0681\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0784\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0665\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0776\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0777\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0646\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0678\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0662\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0776\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0661\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0658\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0789\n",
      "Epoch: 29/30... Training loss: 0.0678\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0669\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0671\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0669\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0668\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0789\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0629\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0664\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0671\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0794\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0667\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0797\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0781\n",
      "Epoch: 29/30... Training loss: 0.0664\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0796\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0793\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0802\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0646\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0791\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0791\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0671\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0664\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0674\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0790\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0791\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0781\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0662\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0652\n",
      "Epoch: 29/30... Training loss: 0.0781\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0794\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0789\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0774\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0790\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0656\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0800\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0665\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0669\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0795\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0760\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0792\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0799\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0671\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0774\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0657\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0803\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0780\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0678\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0797\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0657\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0668\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0668\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0673\n",
      "Epoch: 30/30... Training loss: 0.0680\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0790\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0673\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0663\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0675\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0786\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0793\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0772\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0648\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0778\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0813\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0789\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0677\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0638\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0663\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0805\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0813\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0675\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0781\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0786\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0679\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0788\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0680\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0660\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0666\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0790\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0804\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0781\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0659\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0807\n",
      "Epoch: 30/30... Training loss: 0.0790\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0649\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0673\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0797\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0635\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0676\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0797\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0676\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0772\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0659\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0676\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0787\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0801\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0772\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0798\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0815\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0781\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0790\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0789\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0778\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0788\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0667\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0792\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0673\n",
      "Epoch: 30/30... Training loss: 0.0799\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0781\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0668\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0652\n",
      "Epoch: 30/30... Training loss: 0.0680\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0716\n"
     ]
    }
   ],
   "source": [
    "info = {'losses':[]}\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    mini_batches = prepare_mini_batches(images_for_autoencoder, images_for_autoencoder_labels, batch_size)\n",
    "\n",
    "    epoch_losses = []\n",
    "    while mini_batches:\n",
    "        data_inputs, data_labels = mini_batches.pop()\n",
    "        \n",
    "        # target for net is to decrease image size (encode) and return the same image as inserted (decode)\n",
    "        session.run(optimizer, feed_dict={inputs_: data_inputs, \n",
    "                                          targets_: data_inputs, \n",
    "                                          learning_rate_: learning_rate})\n",
    "        \n",
    "        batch_loss = session.run(cost_value, feed_dict={inputs_: data_inputs, \n",
    "                                                        targets_: data_inputs})\n",
    "        epoch_losses.append(batch_loss)\n",
    "    \n",
    "        print(\"Epoch: {}/{}...\".format(epoch + 1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_loss))\n",
    "        \n",
    "    info['losses'].extend(epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results - image encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# picking test image which autoencoder haven't seen yet\n",
    "test_index = 123\n",
    "random_test_image = test_images[test_index]\n",
    "random_test_image_label = test_images_labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 64 numbers:\n",
      "\n",
      "[  7.20768452   4.99775219   7.13565159   8.24898434   5.41311598\n",
      "  11.4199934    3.05521774   2.05365062   9.42010498   4.89260483\n",
      "   3.89611864  10.08764744   4.87136793   8.86181164   8.27620888\n",
      "   2.12165165  10.0249939    6.24119377   7.52916574   4.24430656\n",
      "   5.26185942   9.21225166   6.29260111   7.65782022   8.10124683\n",
      "   8.80663872   1.21091485   2.10663939   9.47534561   3.11791039\n",
      "  13.43519783   1.29461956   4.59681225   6.18110943   8.88375759\n",
      "   1.40989447   9.16298008   8.46777534   6.25092506   7.48015404\n",
      "   8.46636486   3.79802537   9.22181511   5.90475225   4.99473858\n",
      "   6.15555859   8.10686111   5.56069899   1.83412254   5.42360353\n",
      "   8.11707878   7.01874208   5.48131371   7.04362011  14.14540863\n",
      "   7.90773678   8.09626007   6.61181307   0.7662183    3.92734528\n",
      "   4.95432568   7.12466049  10.56621075   3.56970692]\n",
      "\n",
      "Represents an image: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzIBddTGpyYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192e0940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We can use encoding to pass it to trained model and decode data: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e7e2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding image into `encoding size` values\n",
    "encoded_test_image = session.run([encoded], feed_dict={inputs_: [random_test_image]})\n",
    "\n",
    "# encoding presentation\n",
    "print(\"Following \" + str(len(encoded_test_image[0][0])) + \" numbers:\\n\")\n",
    "print(encoded_test_image[0][0])\n",
    "print(\"\\nRepresents an image: \")\n",
    "plt.imshow(random_test_image.reshape(28, 28), cmap=\"gray_r\")\n",
    "plt.show()\n",
    "\n",
    "# decoding -> recreating image from `encoding size` numbers array\n",
    "print(\"\\nWe can use encoding to pass it to trained model and decode data: \")\n",
    "decoded_test_image = session.run([decoded], feed_dict={encoded: [encoded_test_image[0][0]]})\n",
    "\n",
    "# decoding presentation\n",
    "plt.imshow(decoded_test_image[0][0].reshape((28, 28)), cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More results: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b8a0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9rknktAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c19198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC1MR/iERCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119bf8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAACAAPw/WhAosBya63gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1204bac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1196332e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqp3jEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120353b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_rows_to_show = 6\n",
    "\n",
    "print(\"More results: \")\n",
    "for i in range(example_rows_to_show):\n",
    "    figure, axes = plt.subplots(nrows=2, ncols=8, sharex=True, sharey=True, figsize=(20,4))\n",
    "    images = test_images[(i*8):(i+1)*8]\n",
    "    encodings, decodings = session.run([encoded, decoded], feed_dict={inputs_: images})\n",
    "    \n",
    "    for images_and_decodings, plot_row in zip([images, decodings], axes):\n",
    "        for img, ax in zip(images_and_decodings, plot_row):\n",
    "            ax.imshow(img.reshape((28, 28)), cmap='gray_r')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
