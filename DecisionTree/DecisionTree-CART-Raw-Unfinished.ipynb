{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# info: https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "# source: https://github.com/pandas-dev/pandas/blob/master/pandas/tests/data/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading files & extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset found in directory './iris_dataset/':\n",
      "- iris.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIRECTORY = \"./iris_dataset/\"\n",
    "\n",
    "if os.path.isdir(DATASET_DIRECTORY):\n",
    "    print(\"Iris dataset found in directory '\" + DATASET_DIRECTORY + \"':\")\n",
    "    for file in os.listdir(DATASET_DIRECTORY):\n",
    "        print(\"- \"  + file)\n",
    "else:\n",
    "    print(\"Missing Iris data folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_headers = None\n",
    "iris_rows = None\n",
    "iris_labels = None\n",
    "\n",
    "with open(DATASET_DIRECTORY + \"iris.csv\", \"r\") as csv_file:\n",
    "    temp = list(csv.reader(csv_file))\n",
    "    iris_headers = temp[0]\n",
    "    iris_rows = np.array([np.array(row[:-1]).astype(np.float32) for row in temp[1:]])\n",
    "    iris_labels = [row[-1] for row in temp[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_to_show = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Name']\n"
     ]
    }
   ],
   "source": [
    "print(iris_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample no. 0 - [ 5.0999999   3.5         1.39999998  0.2       ]\n",
      "Sample no. 1 - [ 4.9000001   3.          1.39999998  0.2       ]\n",
      "Sample no. 2 - [ 4.69999981  3.20000005  1.29999995  0.2       ]\n",
      "Sample no. 3 - [ 4.5999999  3.0999999  1.5        0.2      ]\n",
      "Sample no. 4 - [ 5.          3.5999999   1.39999998  0.2       ]\n",
      "Sample no. 5 - [ 5.4000001   3.9000001   1.70000005  0.40000001]\n",
      "Sample no. 6 - [ 4.5999999   3.4000001   1.39999998  0.30000001]\n",
      "Sample no. 7 - [ 5.         3.4000001  1.5        0.2      ]\n",
      "Sample no. 8 - [ 4.4000001   2.9000001   1.39999998  0.2       ]\n",
      "Sample no. 9 - [ 4.9000001  3.0999999  1.5        0.1      ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, rows_to_show):\n",
    "    print(\"Sample no. \" + str(i) + \" - \" + str(iris_rows[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label no. 0 - Iris-setosa\n",
      "Label no. 1 - Iris-setosa\n",
      "Label no. 2 - Iris-setosa\n",
      "Label no. 3 - Iris-setosa\n",
      "Label no. 4 - Iris-setosa\n",
      "Label no. 5 - Iris-setosa\n",
      "Label no. 6 - Iris-setosa\n",
      "Label no. 7 - Iris-setosa\n",
      "Label no. 8 - Iris-setosa\n",
      "Label no. 9 - Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, rows_to_show):\n",
    "    print(\"Label no. \" + str(i) + \" - \" + str(iris_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 150\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \" + str(len(iris_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes will be divided so each set contains same amount of each class type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected num of different classes: 3\n",
      "{'Iris-virginica', 'Iris-setosa', 'Iris-versicolor'}\n"
     ]
    }
   ],
   "source": [
    "classes = set(iris_labels)\n",
    "num_of_classes = len(classes)\n",
    "print(\"Detected num of different classes: \" + str(num_of_classes))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_divided_by_classes = dict()\n",
    "for row, label in zip(iris_rows, iris_labels):\n",
    "    if label not in samples_divided_by_classes.keys():\n",
    "        samples_divided_by_classes.update({label: list()})\n",
    "    \n",
    "    samples_divided_by_classes[label].append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting into train, validation, test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_samples_ratio = 0.65\n",
    "val_test_samples_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting number of remaining samples to split: \n",
      "- Class: Iris-setosa, num samples: 50\n",
      "- Class: Iris-versicolor, num samples: 50\n",
      "- Class: Iris-virginica, num samples: 50\n",
      "\n",
      "Trimming data: \n",
      "- Trimming samples of class 'Iris-virginica'to 50.\n",
      "- Trimming samples of class 'Iris-setosa'to 50.\n",
      "- Trimming samples of class 'Iris-versicolor'to 50.\n",
      "\n",
      "Creating training set: \n",
      "- Adding 32 samples of class 'Iris-virginica' to training set.\n",
      "- Adding 32 samples of class 'Iris-setosa' to training set.\n",
      "- Adding 32 samples of class 'Iris-versicolor' to training set.\n",
      "\n",
      "Counting number of remaining samples to split: \n",
      "- Class: Iris-setosa, num samples: 18\n",
      "- Class: Iris-versicolor, num samples: 18\n",
      "- Class: Iris-virginica, num samples: 18\n",
      "\n",
      "Creating validation and train set: \n",
      "- Adding 9 samples of class 'Iris-virginica' to validation set.\n",
      "- Adding 9 samples of class 'Iris-virginica' to test set.\n",
      "- Adding 9 samples of class 'Iris-setosa' to validation set.\n",
      "- Adding 9 samples of class 'Iris-setosa' to test set.\n",
      "- Adding 9 samples of class 'Iris-versicolor' to validation set.\n",
      "- Adding 9 samples of class 'Iris-versicolor' to test set.\n",
      "\n",
      "Converting types to ndarray.\n"
     ]
    }
   ],
   "source": [
    "train_rows = list()\n",
    "val_rows = list()\n",
    "test_rows = list()\n",
    "\n",
    "train_labels = list()\n",
    "val_labels = list()\n",
    "test_labels = list()\n",
    "\n",
    "print(\"Counting number of remaining samples to split: \")\n",
    "num_of_samples_per_class = list()\n",
    "for key in samples_divided_by_classes.keys():\n",
    "    num_of_samples_per_class.append(len(samples_divided_by_classes[key]))\n",
    "    print(\"- Class: \" + key + \", num samples: \" + str(len(samples_divided_by_classes[key])))\n",
    "\n",
    "print(\"\\nTrimming data: \")\n",
    "for sample_class in classes:\n",
    "    samples_divided_by_classes[sample_class] = samples_divided_by_classes[sample_class][:min(num_of_samples_per_class)]\n",
    "    print(\"- Trimming samples of class '\" + sample_class + \"'to \" + str(min(num_of_samples_per_class)) + \".\")\n",
    "\n",
    "print(\"\\nCreating training set: \")\n",
    "split_index = int(min(num_of_samples_per_class) * test_samples_ratio)\n",
    "for sample_class in classes:\n",
    "    train_rows.extend(samples_divided_by_classes[sample_class][:split_index])\n",
    "    train_labels = [sample_class for sample in train_rows]\n",
    "    print(\"- Adding \" + str(len(samples_divided_by_classes[sample_class][:split_index])) + \" samples of class '\"\n",
    "          + sample_class + \"' to training set.\")\n",
    "    samples_divided_by_classes[sample_class] = samples_divided_by_classes[sample_class][split_index:]\n",
    "\n",
    "print(\"\\nCounting number of remaining samples to split: \")\n",
    "num_of_samples_per_class = list()\n",
    "for key in samples_divided_by_classes.keys():\n",
    "    num_of_samples_per_class.append(len(samples_divided_by_classes[key]))\n",
    "    print(\"- Class: \" + key + \", num samples: \" + str(len(samples_divided_by_classes[key])))\n",
    "\n",
    "print(\"\\nCreating validation and train set: \")\n",
    "split_index = int(min(num_of_samples_per_class) * val_test_samples_ratio)\n",
    "for sample_class in classes:\n",
    "    val_rows.extend(samples_divided_by_classes[sample_class][:split_index])\n",
    "    val_labels = [sample_class for sample in val_rows]\n",
    "    print(\"- Adding \" + str(len(samples_divided_by_classes[sample_class][:split_index])) + \" samples of class '\"\n",
    "          + sample_class + \"' to validation set.\")\n",
    "    \n",
    "    test_rows.extend(samples_divided_by_classes[sample_class][split_index:])\n",
    "    test_labels = [sample_class for sample in test_rows]\n",
    "    print(\"- Adding \" + str(len(samples_divided_by_classes[sample_class][split_index:])) + \" samples of class '\"\n",
    "          + sample_class + \"' to test set.\")\n",
    "    \n",
    "print(\"\\nConverting types to ndarray.\")\n",
    "train_data = np.array([(sample, label) for sample, label in zip(train_rows, train_labels)])\n",
    "train_rows = np.array(train_rows)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "val_rows = np.array(val_rows)\n",
    "test_rows = np.array(test_rows)\n",
    "\n",
    "\n",
    "val_labels = np.array(val_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data samples: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data samples: \" + str(len(train_data)))\n",
    "# print(\"Validation data samples: \" + str(len(val_rows)))\n",
    "# print(\"Test data samples: \" + str(len(test_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self): \n",
    "        self.root = None\n",
    "    \n",
    "    def split_samples_by_feature_value_in_sample(self, feature_index, sample, samples, labels):\n",
    "        left_node, right_node = list(), list()\n",
    "\n",
    "        decisive_value_for_split = sample[feature_index]\n",
    "        for sample, label in zip(samples, labels):\n",
    "            if sample[feature_index] <= decisive_value_for_split:\n",
    "                left_node.append((sample, label))\n",
    "            else:\n",
    "                right_node.append((sample, label))\n",
    "\n",
    "        return (left_node, right_node)\n",
    "    \n",
    "    def gini_index(self, left_node, right_node, classes):\n",
    "        gini_purity = 0.0\n",
    "\n",
    "        num_of_classes = len(classes)\n",
    "        left_node_labels = np.array([data_label_pair[1] for data_label_pair in left_node])\n",
    "        right_node_labels = np.array([data_label_pair[1] for data_label_pair in right_node])\n",
    "\n",
    "        for class_ in classes:\n",
    "            if len(left_node_labels) > 0:\n",
    "                num_labels = len(left_node_labels)\n",
    "                left_node_class_proportion = np.divide((left_node_labels == class_).sum(), num_labels)\n",
    "                gini_purity += (left_node_class_proportion * (1.0 - left_node_class_proportion)) \n",
    "\n",
    "            if len(right_node_labels) > 0:\n",
    "                num_labels = len(right_node_labels)\n",
    "                right_node_class_proprtion = np.divide((right_node_labels == class_).sum(), num_labels)\n",
    "                gini_purity += (right_node_class_proprtion * (1.0 - right_node_class_proprtion))\n",
    "\n",
    "        return gini_purity\n",
    "\n",
    "    def best_split(self, data):\n",
    "        split = {\"feature_index\": None, \n",
    "                 \"feature_value\": None, \n",
    "                 \"purity_value\": None, \n",
    "                 \"nodes\": None}\n",
    "\n",
    "        samples = np.array([data_label_pair[0] for data_label_pair in data])\n",
    "        labels = np.array([data_label_pair[1] for data_label_pair in data])\n",
    "\n",
    "        all_classes = set(labels)\n",
    "        num_of_features_per_sample = samples.shape[1]\n",
    "        for feature_index in range(num_of_features_per_sample):\n",
    "            for sample in samples:\n",
    "                left_node, right_node = \\\n",
    "                    self.split_samples_by_feature_value_in_sample(feature_index, sample, samples, labels)\n",
    "                split_purity = self.gini_index(left_node, right_node, all_classes)\n",
    "                    \n",
    "                if split[\"purity_value\"] == None or split_purity < split[\"purity_value\"]:\n",
    "                    class_vote = np.unique(labels, return_counts=True)\n",
    "                    split_data_info = list()\n",
    "                    for class_, count_ in zip(class_vote[0], class_vote[1]):\n",
    "                        split_data_info.append(\"c'\" + str(class_) + \"' - \" + str(count_) \n",
    "                                               + (\" sample\" if count_ == 1 else \" samples\"))\n",
    "                    desc = \"(\" + \", \".join(split_data_info) + \")\"\n",
    "                   \n",
    "                    split = {\"split_info\": desc,\n",
    "                             \"feature_index\": feature_index, \n",
    "                             \"feature_value\": sample[feature_index], \n",
    "                             \"purity_value\": split_purity, \n",
    "                             \"nodes\": {\"left\": left_node, \"right\": right_node}}\n",
    "\n",
    "        return split\n",
    "\n",
    "    def make_terminal_node(self, labels):\n",
    "        class_vote = np.unique(labels, return_counts=True)\n",
    "        split_data_info = list()\n",
    "        for class_, count_ in zip(class_vote[0], class_vote[1]):\n",
    "            split_data_info.append(\"c'\" + str(class_) + \"' - \" + str(count_) \n",
    "                                   + (\" sample\" if count_ == 1 else \" samples\"))\n",
    "        desc = \"(\" + \", \".join(split_data_info) + \")\"\n",
    "        return class_vote[0][0], desc\n",
    "\n",
    "    def split(self, previous_split, max_tree_depth, min_split_samples, depth):  \n",
    "        left_node_labels = [data[1] for data in previous_split[\"nodes\"][\"left\"]]\n",
    "        left_node_samples_num = len(previous_split[\"nodes\"][\"left\"])\n",
    "\n",
    "        right_node_labels = [data[1] for data in previous_split[\"nodes\"][\"right\"]]\n",
    "        right_node_samples_num = len(previous_split[\"nodes\"][\"right\"])\n",
    "        \n",
    "        if left_node_samples_num == 0 or right_node_samples_num == 0:  \n",
    "            previous_split[\"nodes\"][\"left\"] = self.make_terminal_node(right_node_labels + left_node_labels)\n",
    "            previous_split[\"nodes\"][\"right\"] = self.make_terminal_node(right_node_labels + left_node_labels)\n",
    "            return\n",
    "\n",
    "        if depth >= max_tree_depth:\n",
    "            previous_split[\"nodes\"][\"left\"] = self.make_terminal_node(left_node_labels)\n",
    "            previous_split[\"nodes\"][\"right\"] = self.make_terminal_node(right_node_labels)\n",
    "            return\n",
    "\n",
    "        if len(previous_split[\"nodes\"][\"left\"]) <= min_split_samples or len(set(left_node_labels)) == 1:\n",
    "            previous_split[\"nodes\"][\"left\"] = self.make_terminal_node(left_node_labels)\n",
    "        else:\n",
    "            previous_split[\"nodes\"][\"left\"] = self.best_split(previous_split[\"nodes\"][\"left\"])\n",
    "            self.split(previous_split[\"nodes\"][\"left\"], max_tree_depth, min_split_samples, (depth + 1))\n",
    "\n",
    "        if len(previous_split[\"nodes\"][\"right\"]) <= min_split_samples or len(set(right_node_labels)) == 1:\n",
    "            previous_split[\"nodes\"][\"right\"] = self.make_terminal_node(right_node_labels)\n",
    "        else:\n",
    "            previous_split[\"nodes\"][\"right\"] = self.best_split(previous_split[\"nodes\"][\"right\"])\n",
    "            self.split(previous_split[\"nodes\"][\"right\"], max_tree_depth, min_split_samples, (depth + 1))\n",
    "\n",
    "    def build(self, data, max_tree_depth, min_split_samples):\n",
    "        self.root = self.best_split(data)\n",
    "        self.split(self.root, max_tree_depth, min_split_samples, 1)\n",
    "        \n",
    "    def draw(self, node, depth=0, comment = \"root\"):\n",
    "        if isinstance(node, dict):\n",
    "            print(\"{}{}: Split [{}]: {} by (feature_index '{}' <- {}):\".format(\"   \"*depth,\n",
    "                                                                        depth,\n",
    "                                                                        comment,\n",
    "                                                                        node[\"split_info\"],\n",
    "                                                                        node[\"feature_index\"],\n",
    "                                                                        node[\"feature_value\"]))\n",
    "            self.draw(node[\"nodes\"][\"left\"], (depth + 1), \"left\")\n",
    "            self.draw(node[\"nodes\"][\"right\"], (depth + 1), \"right\")\n",
    "        else:\n",
    "            print(\"{}{}: Terminal node [{}]: {}\".format(\"   \"*depth, depth, comment, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTree()\n",
    "tree.build(train_data, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot switch from automatic field numbering to manual field specification",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-809-27a7a3eac49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-807-a6642736647f>\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, node, depth, comment)\u001b[0m\n\u001b[1;32m    117\u001b[0m                                                                                                 \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                                                                                                 \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                                                                                                 node[\"purity_value\"]))\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot switch from automatic field numbering to manual field specification"
     ]
    }
   ],
   "source": [
    "print(tree.draw(tree.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=10, min_samples_split=2, criterion='gini', splitter='best')\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"iris.pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data2 = [(sample, label) for sample, label in zip(iris.data, iris.target)]\n",
    "tree = DecisionTree()\n",
    "tree.build(train_data2, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw(tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
